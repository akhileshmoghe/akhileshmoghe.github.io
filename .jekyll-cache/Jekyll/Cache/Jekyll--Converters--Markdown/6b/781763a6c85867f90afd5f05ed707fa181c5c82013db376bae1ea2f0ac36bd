I""<p>This write-up will only focus on AWS Sagemaker ML service with respect to ML model deployment to Edge devices and Cloud.</p>

<h2 id="ml-inference-on-greengrass-devices">ML Inference on Greengrass devices</h2>
<ul>
  <li>ML models can be trained using <strong><em><u>AWS Sagemaker</u></em></strong> or custom ml trainining ways. Models are stored in <strong><em><u>AWS S3</u></em></strong> for deployment to Greengrass devices.</li>
  <li>ML models are deployed as artifacts in your components to perform inference on your core devices.</li>
</ul>

<h3 id="ml-components">ML Components</h3>
<ul>
  <li>AWS provides following Machine Learning components that can be deployed to edge devices to perform Machine Learning Inference.</li>
  <li>ML models can be trained using <strong><em><u>AWS Sagemaker</u></em></strong> or custom ml trainining ways. Models are stored in <strong><em><u>AWS S3</u></em></strong> for deployment to Greengrass devices.</li>
  <li>AWS-provided machine learning components are broadly categorized as follows:
    <ul>
      <li><strong><em>Model component</em></strong> — Contains machine learning models as <em><u>Greengrass artifacts</u></em>.</li>
      <li><strong><em>Runtime component</em></strong> — Contains the <em><u>script</u></em> that installs the machine learning framework and its dependencies on the Greengrass core device.</li>
      <li><strong><em>Inference component</em></strong> — Contains the <em><u>inference code</u></em> and includes <em><u>component dependencies</u></em> to install the machine learning framework and download pre-trained machine learning models.</li>
    </ul>
  </li>
  <li>To perform custom machine learning inference with <em><u>your own models</u></em> that are stored in <strong><em><u>Amazon S3</u></em></strong>, or to use a <em><u>different machine learning framework</u></em>, you can use the recipes of the following public components as templates to create custom machine learning components.
    <ul>
      <li>Further Reference:
        <ul>
          <li><a href="https://docs.aws.amazon.com/greengrass/v2/developerguide/ml-customization.html">Customize your machine learning components</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>AWS provided ML model components:
    <ul>
      <li>SageMaker Edge Manager</li>
      <li>DLR image classification</li>
      <li>DLR object detection</li>
      <li>DLR image classification model store</li>
      <li>DLR object detection model store</li>
      <li>DLR installer</li>
      <li>TensorFlow Lite image classification</li>
      <li>TensorFlow Lite object detection</li>
      <li>TensorFlow Lite image classification model store</li>
      <li>TensorFlow Lite object detection model store</li>
      <li>TensorFlow Lite installer</li>
    </ul>
  </li>
</ul>

<h3 id="aws-sagemaker-edge-manager-agent">AWS SageMaker Edge Manager agent</h3>
<ul>
  <li>With SageMaker Edge Manager, you can use Amazon SageMaker Neo-compiled models directly on your core device.</li>
  <li><a href="/on-premise%20cloud/cloud/aws/edge%20iot/ml/2021/11/11/AWS-SageMaker.html">AWS SageMaker Edge Manager</a></li>
</ul>

<h2 id="further-references">Further References</h2>
<ul>
  <li><a href="https://github.com/aws-samples/greengrass-v2-docker-ros-demo">ROS2 Docker Sample Application with AWS IoT Greengrass 2.0</a></li>
</ul>

:ET