<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-12-12T20:48:43+05:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">Every THING is Internet of Thing</title><subtitle>A Journey in the direction of ---&gt; IoT ---&gt; Edge ---&gt; Cloud ---&gt; DevOps ---&gt; ML ---&gt; AI
</subtitle><author><name>Akhilesh Moghe</name><email>akhileshmoghe@live.com</email></author><entry><title type="html">Linux Boot Process</title><link href="http://localhost:4000/_post/linux/boot_process" rel="alternate" type="text/html" title="Linux Boot Process" /><published>2021-12-12T01:33:22+05:30</published><updated>2021-12-12T01:33:22+05:30</updated><id>http://localhost:4000/_post/linux/Boot-process</id><content type="html" xml:base="http://localhost:4000/_post/linux/boot_process">&lt;p&gt;This article will focus on different stages of boot process in Linux OS.
There are 6 distinct stages of boot process, each explained in brief as below.
There’s also a note on &lt;em&gt;&lt;u&gt;runlevels&lt;/u&gt;&lt;/em&gt; which represents the state of the system after boot, which are usually managed by systemd.&lt;/p&gt;

&lt;p&gt;Embedded Linux boot process similar to standard Linux to much extent, but due to the variations in hadware and the board specifics like multi-stage bootloaders, it becomes somewhat different in bootloader section and pre-dominant use of &lt;strong&gt;&lt;em&gt;u-Boot&lt;/em&gt;&lt;/strong&gt; bootloader in embedded systems also needs to be addressed. To find out specifics of &lt;a href=&quot;/_post/embedded/linux/boot_process&quot;&gt;Embedded Linux Boot Process&lt;/a&gt; see this article.&lt;/p&gt;

&lt;h2 id=&quot;1-bios-basic-inputoutput-system&quot;&gt;1. BIOS (Basic Input/Output System)&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;BIOS is a program that controls computer’s hardware from the time the computer is started until the main operating system takes over.&lt;/li&gt;
  &lt;li&gt;BIOS first performs some &lt;em&gt;&lt;u&gt;integrity checks&lt;/u&gt;&lt;/em&gt;, i.e. &lt;em&gt;&lt;u&gt;power on self test&lt;/u&gt;&lt;/em&gt; (POST) of the &lt;strong&gt;HDD&lt;/strong&gt; or &lt;strong&gt;SSD&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;BIOS acts as an intermediary between the CPU and the input and output devices. This eliminates the need for the operating system to be aware of the hardware addresses of the input and output devices.&lt;/li&gt;
  &lt;li&gt;When there’s a change in device details, only the BIOS Configuration needs to be updated. (accomplished by pressing a specified key F12 or F2 as soon as the computer begins to start up).&lt;/li&gt;
  &lt;li&gt;BIOS program, written in the &lt;em&gt;&lt;u&gt;assembly language&lt;/u&gt;&lt;/em&gt; of the CPU used, is stored on &lt;strong&gt;&lt;em&gt;Electrically Erasable Programmable ROM (EEPROM)&lt;/em&gt;&lt;/strong&gt; or &lt;strong&gt;&lt;em&gt;flash&lt;/em&gt;&lt;/strong&gt; memory.&lt;/li&gt;
  &lt;li&gt;BIOS searches for, loads, and executes the boot loader program.&lt;/li&gt;
  &lt;li&gt;BIOS loads and executes the &lt;strong&gt;&lt;em&gt;Master Boot Record (MBR)&lt;/em&gt;&lt;/strong&gt; boot loader.&lt;/li&gt;
  &lt;li&gt;BIOSs permit the user to select the order in which the system searches for &lt;em&gt;&lt;u&gt;bootable media&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;MBR is usually on HDD or SSD, but sometimes on a USB stick or CD-ROM such as with a live installation of Linux.&lt;/li&gt;
  &lt;li&gt;Once the boot loader is loaded into memory and the BIOS gives control of the system to it.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-master-boot-record-mbr&quot;&gt;2. Master Boot Record (MBR)&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;MBR is responsible for loading and executing the &lt;strong&gt;&lt;em&gt;GRUB&lt;/em&gt;&lt;/strong&gt; boot loader.&lt;/li&gt;
  &lt;li&gt;MBR is located in the &lt;em&gt;&lt;u&gt;1st sector&lt;/u&gt;&lt;/em&gt; of the bootable disk, which is typically &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/dev/hda&lt;/code&gt;, or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/dev/sda&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;MBR is less than &lt;em&gt;&lt;u&gt;512 bytes&lt;/u&gt;&lt;/em&gt; in size. This has three components 1) &lt;em&gt;&lt;u&gt;primary boot loader info&lt;/u&gt;&lt;/em&gt; in 1st 446 bytes 2) &lt;em&gt;&lt;u&gt;partition table info&lt;/u&gt;&lt;/em&gt; in next 64 bytes 3) &lt;em&gt;&lt;u&gt;mbr validation check&lt;/u&gt;&lt;/em&gt; in last 2 bytes.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-gnu-grand-unified-bootloader-grub&quot;&gt;3. GNU GRand Unified Bootloader (GRUB)&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;GRUB is the typical boot loader for most modern Linux systems.&lt;/li&gt;
  &lt;li&gt;GRUB Splash Screen is the first to appear on screen. If you have multiple kernel images installed, you can use your keyboard to select the one you want your system to boot with.&lt;/li&gt;
  &lt;li&gt;GRUB configuration file is usually at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/boot/grub/grub.conf&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/grub.conf&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-kernel&quot;&gt;4. Kernel&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;The Kernel that was selected by GRUB first mounts the &lt;strong&gt;&lt;em&gt;root file system&lt;/em&gt;&lt;/strong&gt; that’s specified in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grub.conf&lt;/code&gt; file.&lt;/li&gt;
  &lt;li&gt;Then Kernel executes the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/sbin/init&lt;/code&gt; program, which is *&lt;u&gt;always the first program to be executed&lt;/u&gt;. You can confirm this with its *&lt;u&gt;process id (PID)&lt;/u&gt;, which should always be &lt;strong&gt;1&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;The kernel then establishes &lt;em&gt;&lt;u&gt;a temporary root file system&lt;/u&gt;&lt;/em&gt; using &lt;strong&gt;&lt;em&gt;Initial RAM Disk (initrd)&lt;/em&gt;&lt;/strong&gt; until the real file system is mounted.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-init&quot;&gt;5. Init&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;With Init stage, system executes runlevel programs. System looks for an init file &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/inittab&lt;/code&gt; to decide the Linux run level.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-runlevel-programs&quot;&gt;6. Runlevel Programs&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;A runlevel is a mode of operation in the computer operating systems that implements Unix System V-style initialization.&lt;/li&gt;
  &lt;li&gt;Conventionally, &lt;em&gt;&lt;u&gt;seven runlevels&lt;/u&gt;&lt;/em&gt; exist, numbered from zero to six.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;&lt;u&gt;Only one runlevel is executed on startup&lt;/u&gt;&lt;/em&gt;; run levels are &lt;em&gt;&lt;u&gt;not executed one after another&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;A runlevel defines the state of the machine after boot&lt;/em&gt;&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;By default most of the LINUX based system boots to runlevel 3 or runlevel 5.&lt;/li&gt;
  &lt;li&gt;Depending on your default init level setting, which are usually managed by &lt;strong&gt;&lt;em&gt;systemd&lt;/em&gt;&lt;/strong&gt;, the system will execute the start scripts for each run level are different performing different tasks. These start scripts corresponding to each run level can be found in special files present under &lt;strong&gt;&lt;em&gt;rc sub directories&lt;/em&gt;&lt;/strong&gt;.
    &lt;ul&gt;
      &lt;li&gt;At &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/rc.d&lt;/code&gt; directory there will be either a set of files named &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rc.0&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rc.1&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rc.2&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rc.3&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rc.4&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rc.5&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rc.6&lt;/code&gt;, or a set of directories named &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rc0.d&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rc1.d&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rc2.d&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rc3.d&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rc4.d&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rc5.d&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rc6.d&lt;/code&gt;.&lt;/li&gt;
      &lt;li&gt;In these directories, you’ll find programs that start with either an “&lt;strong&gt;&lt;em&gt;S&lt;/em&gt;&lt;/strong&gt;” or “&lt;strong&gt;&lt;em&gt;K&lt;/em&gt;&lt;/strong&gt;” for &lt;em&gt;&lt;u&gt;startup&lt;/u&gt;&lt;/em&gt; and &lt;em&gt;&lt;u&gt;kill&lt;/u&gt;&lt;/em&gt;, respectively. Startup programs are executed during &lt;em&gt;&lt;u&gt;system startup&lt;/u&gt;&lt;/em&gt;, and kill programs during &lt;em&gt;&lt;u&gt;shutdown&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
      &lt;li&gt;There are numbers right next to S and K in the program names. Those are the &lt;em&gt;&lt;u&gt;sequence number&lt;/u&gt;&lt;/em&gt; in which the programs should be started or killed.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@PTL011669:# cd /etc/rc0.d/
root@PTL011669:rc0.d# ls
K01alsa-utils           K01avahi-daemon    K01docker         K01kerneloops     K01mdadm-waitidle  K01rpcbind
K01spice-vdagent        K01apache2         K01bluetooth      K01etc-setserial  K01lighttpd        K01mosquitto
K01rsyslog              K01unattended-upgrades               K01apache-htcacheclean               K01cgroupfs-mount
K01gdm3                 K01lvm2-lvmetad    K01networking     K01saned          K01uuidd           K01atop
K01chrony               K01hddtemp         K01lvm2-lvmpolld  K01plymouth       K01setserial       K01virtualbox
K01atopacct             K01cups-browsed    K01irqbalance     K01mdadm          K01postfix         K01speech-dispatcher
root@PTL011669:rc0.d# 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Changing runlevel&lt;/em&gt;&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;init&lt;/em&gt;&lt;/strong&gt; is the program responsible for altering the run level which can be called using &lt;strong&gt;&lt;em&gt;telinit&lt;/em&gt;&lt;/strong&gt; command.&lt;/li&gt;
      &lt;li&gt;&lt;u&gt;Need for changing the runlevel&lt;/u&gt;:
        &lt;ul&gt;
          &lt;li&gt;There can be a situation when you may find &lt;em&gt;&lt;u&gt;trouble in logging&lt;/u&gt;&lt;/em&gt; in in case you don’t remember the password or because of the corrupted &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/passwd&lt;/code&gt; file, in this case the problem can be solved by booting into a single user mode i.e runlevel 1.&lt;/li&gt;
          &lt;li&gt;You can easily &lt;em&gt;&lt;u&gt;halt the system&lt;/u&gt;&lt;/em&gt; by changing the runlevel to 0 by using telinit 0.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Standard runlevels&lt;/em&gt;&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;ID&lt;/th&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;Off&lt;/td&gt;
      &lt;td&gt;Turns off the device.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;Single User mode&lt;/td&gt;
      &lt;td&gt;Mode for administrative tasks.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Multi-user mode&lt;/td&gt;
      &lt;td&gt;Does not configure network interfaces and does not export networks services.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;Multi-user mode with networking&lt;/td&gt;
      &lt;td&gt;Starts the system normally.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;Not used/user-definable&lt;/td&gt;
      &lt;td&gt;For special purposes.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;Full mode&lt;/td&gt;
      &lt;td&gt;Same as runlevel 3 + display manager.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;Reboot&lt;/td&gt;
      &lt;td&gt;Reboots the device.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;references&quot;&gt;References:&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.linfo.org/bios.html&quot;&gt;BIOS&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Runlevel&quot;&gt;Runlevels&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.geeksforgeeks.org/run-levels-linux/&quot;&gt;Runlevels&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.freecodecamp.org/news/the-linux-booting-process-6-steps-described-in-detail/&quot;&gt;The Linux Booting Process - 6 Steps Described in Detail&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Akhilesh Moghe</name></author><category term="Linux" /><category term="Embedded Linux" /><category term="Bootloader" /><category term="Linux" /><category term="Embedded Linux" /><category term="Bootloader" /><summary type="html">This article will focus on different stages of boot process in Linux OS. There are 6 distinct stages of boot process, each explained in brief as below. There’s also a note on runlevels which represents the state of the system after boot, which are usually managed by systemd. Embedded Linux boot process similar to standard Linux to much extent, but due to the variations in hadware and the board specifics like multi-stage bootloaders, it becomes somewhat different in bootloader section and pre-dominant use of u-Boot bootloader in embedded systems also needs to be addressed. To find out specifics of Embedded Linux Boot Process see this article. 1. BIOS (Basic Input/Output System) BIOS is a program that controls computer’s hardware from the time the computer is started until the main operating system takes over. BIOS first performs some integrity checks, i.e. power on self test (POST) of the HDD or SSD. BIOS acts as an intermediary between the CPU and the input and output devices. This eliminates the need for the operating system to be aware of the hardware addresses of the input and output devices. When there’s a change in device details, only the BIOS Configuration needs to be updated. (accomplished by pressing a specified key F12 or F2 as soon as the computer begins to start up). BIOS program, written in the assembly language of the CPU used, is stored on Electrically Erasable Programmable ROM (EEPROM) or flash memory. BIOS searches for, loads, and executes the boot loader program. BIOS loads and executes the Master Boot Record (MBR) boot loader. BIOSs permit the user to select the order in which the system searches for bootable media. MBR is usually on HDD or SSD, but sometimes on a USB stick or CD-ROM such as with a live installation of Linux. Once the boot loader is loaded into memory and the BIOS gives control of the system to it. 2. Master Boot Record (MBR) MBR is responsible for loading and executing the GRUB boot loader. MBR is located in the 1st sector of the bootable disk, which is typically /dev/hda, or /dev/sda. MBR is less than 512 bytes in size. This has three components 1) primary boot loader info in 1st 446 bytes 2) partition table info in next 64 bytes 3) mbr validation check in last 2 bytes. 3. GNU GRand Unified Bootloader (GRUB) GRUB is the typical boot loader for most modern Linux systems. GRUB Splash Screen is the first to appear on screen. If you have multiple kernel images installed, you can use your keyboard to select the one you want your system to boot with. GRUB configuration file is usually at /boot/grub/grub.conf or /etc/grub.conf. 4. Kernel The Kernel that was selected by GRUB first mounts the root file system that’s specified in the grub.conf file. Then Kernel executes the /sbin/init program, which is *always the first program to be executed. You can confirm this with its *process id (PID), which should always be 1. The kernel then establishes a temporary root file system using Initial RAM Disk (initrd) until the real file system is mounted. 5. Init With Init stage, system executes runlevel programs. System looks for an init file /etc/inittab to decide the Linux run level. 6. Runlevel Programs A runlevel is a mode of operation in the computer operating systems that implements Unix System V-style initialization. Conventionally, seven runlevels exist, numbered from zero to six. Only one runlevel is executed on startup; run levels are not executed one after another. A runlevel defines the state of the machine after boot. By default most of the LINUX based system boots to runlevel 3 or runlevel 5. Depending on your default init level setting, which are usually managed by systemd, the system will execute the start scripts for each run level are different performing different tasks. These start scripts corresponding to each run level can be found in special files present under rc sub directories. At /etc/rc.d directory there will be either a set of files named rc.0, rc.1, rc.2, rc.3, rc.4, rc.5 and rc.6, or a set of directories named rc0.d, rc1.d, rc2.d, rc3.d, rc4.d, rc5.d and rc6.d. In these directories, you’ll find programs that start with either an “S” or “K” for startup and kill, respectively. Startup programs are executed during system startup, and kill programs during shutdown. There are numbers right next to S and K in the program names. Those are the sequence number in which the programs should be started or killed. root@PTL011669:# cd /etc/rc0.d/ root@PTL011669:rc0.d# ls K01alsa-utils K01avahi-daemon K01docker K01kerneloops K01mdadm-waitidle K01rpcbind K01spice-vdagent K01apache2 K01bluetooth K01etc-setserial K01lighttpd K01mosquitto K01rsyslog K01unattended-upgrades K01apache-htcacheclean K01cgroupfs-mount K01gdm3 K01lvm2-lvmetad K01networking K01saned K01uuidd K01atop K01chrony K01hddtemp K01lvm2-lvmpolld K01plymouth K01setserial K01virtualbox K01atopacct K01cups-browsed K01irqbalance K01mdadm K01postfix K01speech-dispatcher root@PTL011669:rc0.d# Changing runlevel: init is the program responsible for altering the run level which can be called using telinit command. Need for changing the runlevel: There can be a situation when you may find trouble in logging in in case you don’t remember the password or because of the corrupted /etc/passwd file, in this case the problem can be solved by booting into a single user mode i.e runlevel 1. You can easily halt the system by changing the runlevel to 0 by using telinit 0. Standard runlevels: ID Name Description 0 Off Turns off the device. 1 Single User mode Mode for administrative tasks. 2 Multi-user mode Does not configure network interfaces and does not export networks services. 3 Multi-user mode with networking Starts the system normally. 4 Not used/user-definable For special purposes. 5 Full mode Same as runlevel 3 + display manager. 6 Reboot Reboots the device. References: BIOS Runlevels Runlevels The Linux Booting Process - 6 Steps Described in Detail</summary></entry><entry><title type="html">Typical Embedded Linux Boot Process</title><link href="http://localhost:4000/_post/embedded/linux/boot_process" rel="alternate" type="text/html" title="Typical Embedded Linux Boot Process" /><published>2021-12-12T01:33:22+05:30</published><updated>2021-12-12T01:33:22+05:30</updated><id>http://localhost:4000/_post/embedded/linux/Embedded-Linux-Boot-process</id><content type="html" xml:base="http://localhost:4000/_post/embedded/linux/boot_process">&lt;p&gt;Usually, there are 6 distinct stages of boot process, each explained in brief in &lt;a href=&quot;/_post/linux/boot_process&quot;&gt;Linux Boot Process&lt;/a&gt; article.
This article will focus on different stages of boot process Specifically in Embedded Linux.
Though the content and screenshots in this article are for BeagleBone board, the boot process is almost similar in general.&lt;/p&gt;

&lt;h2 id=&quot;embedded-linux-booting-process-multi-stage-bootloaders-kernel-filesystem&quot;&gt;Embedded Linux Booting Process (Multi-Stage Bootloaders, Kernel, Filesystem)&lt;/h2&gt;
&lt;iframe width=&quot;665&quot; height=&quot;374&quot; src=&quot;https://www.youtube.com/embed/DV5S_ZSdK0s&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;ul&gt;
  &lt;li&gt;In this video, we will look at how the BeagleBone Black boots into an embedded Linux system. We will understand how the &lt;strong&gt;&lt;em&gt;ROM Bootloader&lt;/em&gt;&lt;/strong&gt; works for the AM335x SoC series, the first and second stage bootloaders (&lt;strong&gt;&lt;em&gt;SPL/MLO&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;U-Boot&lt;/em&gt;&lt;/strong&gt;) and how to load the kernel, device tree, filesystem and user space processes.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;embedded-linux-boot-process&quot;&gt;Embedded Linux Boot Process:&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/embedded/boot/embedded_linux_boot_process.png&quot; alt=&quot;Embedded Linux Boot Process&quot; class=&quot;shadow&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;embedded-linux-boot-sequence&quot;&gt;Embedded Linux Boot Sequence:&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/embedded/boot/embedded_linux_boot_sequence.png&quot; alt=&quot;Embedded Linux Boot Sequence&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The variation in the boot process is typically only in the first couple of Steps, i.e. how does a &lt;strong&gt;&lt;em&gt;ROM Bootloader&lt;/em&gt;&lt;/strong&gt; loads the &lt;strong&gt;&lt;em&gt;u-boot&lt;/em&gt;&lt;/strong&gt; in RAM and passes control to it. These steps will be something board specific.&lt;/li&gt;
  &lt;li&gt;Once the &lt;strong&gt;&lt;em&gt;u-boot&lt;/em&gt;&lt;/strong&gt; is in memory, rest of the steps are standard.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;why-the-1st-stage-bootloader-mlo-is-required-at-all&quot;&gt;Why the 1st stage bootloader (MLO) is required at all?&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;ROM Bootloader has only access to internal RAM by default. As the SoC vendors knows very little about how &amp;amp; which external peripherals the SoC is going to interact with. DRAM/RAM controllers are again a separate vendors.&lt;/li&gt;
  &lt;li&gt;So, ROM Bootloader code cannot assume anything, and can only work on the things it knows, i.e. internal RAM.&lt;/li&gt;
  &lt;li&gt;Internal RAM is usually very limited in size in the range of few Kilo-Bytes, for BeagleBone it’s 128KB.&lt;/li&gt;
  &lt;li&gt;RAM internal to a SoC is very expensive. This is a key reason why multiple stage bootloaders are really required and are common in embedded devices.&lt;/li&gt;
  &lt;li&gt;On the other hand, U-Boot is fairly large program, given the amountof functionality it supports. It cannot be accomodated in internal RAM of the SoC.&lt;/li&gt;
  &lt;li&gt;That’s why MLO or multiple stage bootloaders are required, the MLO understands the interaction with external RAM and can load the u-boot on it.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/_post/embedded/linux/boot_process/jetson_nano#bootloader-components&quot;&gt;NVIDIA® Jetson™ Nano has in all 5 Bootloader stages, including BootROM, which is hard-wired in SoC.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;references&quot;&gt;References:&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=DV5S_ZSdK0s&amp;amp;t=6s&amp;amp;ab_channel=PentesterAcademyTV&quot;&gt;Embedded Linux Booting Process (Multi-Stage Bootloaders, Kernel, Filesystem)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Akhilesh Moghe</name></author><category term="Linux" /><category term="Embedded Linux" /><category term="Bootloader" /><category term="Linux" /><category term="Embedded Linux" /><category term="Bootloader" /><summary type="html">Usually, there are 6 distinct stages of boot process, each explained in brief in Linux Boot Process article. This article will focus on different stages of boot process Specifically in Embedded Linux. Though the content and screenshots in this article are for BeagleBone board, the boot process is almost similar in general. Embedded Linux Booting Process (Multi-Stage Bootloaders, Kernel, Filesystem) In this video, we will look at how the BeagleBone Black boots into an embedded Linux system. We will understand how the ROM Bootloader works for the AM335x SoC series, the first and second stage bootloaders (SPL/MLO and U-Boot) and how to load the kernel, device tree, filesystem and user space processes. Embedded Linux Boot Process: Embedded Linux Boot Sequence: The variation in the boot process is typically only in the first couple of Steps, i.e. how does a ROM Bootloader loads the u-boot in RAM and passes control to it. These steps will be something board specific. Once the u-boot is in memory, rest of the steps are standard. Why the 1st stage bootloader (MLO) is required at all? ROM Bootloader has only access to internal RAM by default. As the SoC vendors knows very little about how &amp;amp; which external peripherals the SoC is going to interact with. DRAM/RAM controllers are again a separate vendors. So, ROM Bootloader code cannot assume anything, and can only work on the things it knows, i.e. internal RAM. Internal RAM is usually very limited in size in the range of few Kilo-Bytes, for BeagleBone it’s 128KB. RAM internal to a SoC is very expensive. This is a key reason why multiple stage bootloaders are really required and are common in embedded devices. On the other hand, U-Boot is fairly large program, given the amountof functionality it supports. It cannot be accomodated in internal RAM of the SoC. That’s why MLO or multiple stage bootloaders are required, the MLO understands the interaction with external RAM and can load the u-boot on it. NVIDIA® Jetson™ Nano has in all 5 Bootloader stages, including BootROM, which is hard-wired in SoC. References: Embedded Linux Booting Process (Multi-Stage Bootloaders, Kernel, Filesystem)</summary></entry><entry><title type="html">NVIDIA L4T Embedded Linux Boot Process for Jetson Nano</title><link href="http://localhost:4000/_post/embedded/linux/boot_process/jetson_nano" rel="alternate" type="text/html" title="NVIDIA L4T Embedded Linux Boot Process for Jetson Nano" /><published>2021-12-12T01:33:22+05:30</published><updated>2021-12-12T01:33:22+05:30</updated><id>http://localhost:4000/_post/embedded/linux/boot_process/Jetson-Nano-Boot-Process</id><content type="html" xml:base="http://localhost:4000/_post/embedded/linux/boot_process/jetson_nano">&lt;h2 id=&quot;jetson-nano-bootloader-functionalities&quot;&gt;Jetson Nano Bootloader functionalities:&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;The primary function of the NVIDIA® Jetson Nano™ boot software is to initialize the SoC (System on a Chip), including:&lt;/li&gt;
  &lt;li&gt;Initializing MC/EMC/CPU&lt;/li&gt;
  &lt;li&gt;Setting up security parameters&lt;/li&gt;
  &lt;li&gt;Loading different firmware&lt;/li&gt;
  &lt;li&gt;Maintaining Chain of Trust&lt;/li&gt;
  &lt;li&gt;Setting memory carveouts for different firmware&lt;/li&gt;
  &lt;li&gt;Flashing the device&lt;/li&gt;
  &lt;li&gt;Booting to the operating system
  Additionally, the Jetson Nano boot software also performs other operations defined by product requirements, including but not limited to:&lt;/li&gt;
  &lt;li&gt;Initialization of HDMI™/DSI&lt;/li&gt;
  &lt;li&gt;Displaying the boot logo&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/embedded/boot/jetson_nano_boot_sequence.png&quot; alt=&quot;jetson_nano_boot_sequence&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;BPMP???&lt;/em&gt;&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;BPMP is NVIDIA Tegra &lt;em&gt;&lt;u&gt;Boot and Power Management Processor&lt;/u&gt;&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;The BPMP is a specific processor in Tegra chip, which is designed for booting process handling and offloading the power management, clock management, and reset control tasks from the CPU.&lt;/li&gt;
      &lt;li&gt;The BPMP firmware driver, which can create the interprocessor communication (IPC) between the CPU and BPMP.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bootloader-components&quot;&gt;Bootloader Components&lt;/h2&gt;
&lt;h3 id=&quot;0-bootrom&quot;&gt;0. BootROM&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Jetson Nano BootROM (BR) is &lt;em&gt;&lt;u&gt;hard-wired in the SoC&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;It initializes the Boot Media and loads bootloaders and firmware from the Boot Media.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Boot Configuration Table (BCT)&lt;/em&gt;&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Multiple copies of the BootROM Boot Configuration Table (BCT) may be stored &lt;em&gt;&lt;u&gt;at the start of the Boot-Media&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
      &lt;li&gt;The BCT contains configuration parameters used by the BootROM for hardware initialization.&lt;/li&gt;
      &lt;li&gt;Bootloader info in BCT:
        &lt;ul&gt;
          &lt;li&gt;Size&lt;/li&gt;
          &lt;li&gt;Entry point&lt;/li&gt;
          &lt;li&gt;Load address&lt;/li&gt;
          &lt;li&gt;Hash&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/images/embedded/boot/bootrom-boot-flow.jpg&quot; alt=&quot;bootrom-boot-flow&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1-tegraboot&quot;&gt;1. TegraBoot&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;TegraBoot (NVTBoot) is the &lt;em&gt;&lt;u&gt;first boot software&lt;/u&gt;&lt;/em&gt; component loaded by BootROM in &lt;em&gt;&lt;u&gt;SysRAM (Internal RAM)&lt;/u&gt;&lt;/em&gt;, and runs on BPMP.&lt;/li&gt;
  &lt;li&gt;2 Types:
    &lt;ul&gt;
      &lt;li&gt;One used for &lt;em&gt;&lt;u&gt;cold boot&lt;/u&gt;&lt;/em&gt; (~hard boot:restart the board)&lt;/li&gt;
      &lt;li&gt;One for &lt;em&gt;&lt;u&gt;recovery boot/flashing&lt;/u&gt;&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Responsibilities:
    &lt;ul&gt;
      &lt;li&gt;Loading and initializing firmware (FW) components such as &lt;strong&gt;&lt;em&gt;TOS&lt;/em&gt;&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;TOS contains the &lt;em&gt;&lt;u&gt;trusted OS binary&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Creating carveouts
        &lt;ul&gt;
          &lt;li&gt;carveouts: It’s share memory for the coprocess.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Completing CPU initialization&lt;/li&gt;
      &lt;li&gt;Loading the next stage bootloader&lt;/li&gt;
      &lt;li&gt;Supporting flashing&lt;/li&gt;
      &lt;li&gt;Supporting RCM boot
        &lt;ul&gt;
          &lt;li&gt;Recovery mode: used during flasing the board&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Reading PMIC reset reason
        &lt;ul&gt;
          &lt;li&gt;PMIC: Power Management IC&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Loading the bootloader device tree and passing the device tree load address to CBoot&lt;/li&gt;
      &lt;li&gt;Stops execution when the CCPLEX is booted
        &lt;ul&gt;
          &lt;li&gt;CCPLEX: main CPU Complex, CCPLEX typically runs the system’s primary software stack.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-tegrboot-cpu&quot;&gt;2. TegrBoot CPU&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Add rollback prevention.&lt;/li&gt;
  &lt;li&gt;Using bootloader DTB(~device tree binary), perform EMC(~Electromagnetic Compatibility) training and update kernel DTB with training results.&lt;/li&gt;
  &lt;li&gt;Pass control to CBoot.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-cboot&quot;&gt;3. CBoot&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;&lt;u&gt;Primary CPU bootloader&lt;/u&gt;&lt;/em&gt; used on mobile platforms in the &lt;em&gt;&lt;u&gt;cold boot&lt;/u&gt;&lt;/em&gt; path.&lt;/li&gt;
  &lt;li&gt;features:
    &lt;ul&gt;
      &lt;li&gt;Supports display and &lt;em&gt;&lt;u&gt;boot logo/bmp splash&lt;/u&gt;&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;Based on the &lt;a href=&quot;https://github.com/littlekernel/lk&quot;&gt;&lt;strong&gt;&lt;em&gt;Little Kernel (LK) open source bootloader&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Uses the interrupt and scheduling frameworks of LK&lt;/li&gt;
      &lt;li&gt;Uses CDF for frameworks, drivers, and libraries&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;BootLoader and kernel use separate device trees stored in separate partitions.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Responsibilities:
    &lt;ul&gt;
      &lt;li&gt;Parsing the CPU-BL parameters and initializing the bootloader device tree&lt;/li&gt;
      &lt;li&gt;Chaining to U-Boot to boot the kernel&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;&lt;u&gt;Supporting the update mechanism&lt;/u&gt;&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;Unhalts the BPMP so that the BPMP-FW can start running&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-u-boot&quot;&gt;4. U-Boot&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;default OS bootloader for NVIDIA® Jetson™ L4T Driver Package.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;partitions&quot;&gt;Partitions&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;L4T&lt;/em&gt;&lt;/strong&gt; supports formatting mass storage media(~SD cards, USB) into &lt;em&gt;&lt;u&gt;multiple partitions&lt;/u&gt;&lt;/em&gt; for storing data, such as the device &lt;em&gt;&lt;u&gt;OS image&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;Bootloader image&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;device firmware&lt;/u&gt;&lt;/em&gt;, and &lt;em&gt;&lt;u&gt;Bootloader splash screens&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;partition-configuration-file&quot;&gt;Partition Configuration file&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Located at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;top&amp;gt;/Linux_for_Tegra/bootloader/t210ref/cfg/&lt;/code&gt; for Jetson Nano devices&lt;/li&gt;
  &lt;li&gt;NVIDIA Jetson Nano (SKU 0000): flash_l4t_t210_max-spi_sd_p3448.xml&lt;/li&gt;
  &lt;li&gt;NVIDIA Jetson Nano (SKU 0002): flash_l4t_t210_emmc_p3448.xml&lt;/li&gt;
  &lt;li&gt;During the flashing procedure, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;flash.sh&lt;/code&gt; reads in the partition configuration file, translates keywords into values specified in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;device&amp;gt;.conf&lt;/code&gt; or in option parameters and saves the data in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bootloader/flash.xml&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Then &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__*bootloader/tegraflash.py*__&lt;/code&gt; reads in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bootloader/flash.xml&lt;/code&gt; and &lt;em&gt;&lt;u&gt;performs actual flashing&lt;/u&gt;&lt;/em&gt; as specified by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bootloader/flash.xml&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;partition-table-overview&quot;&gt;Partition Table Overview&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Describe partition use for the &lt;em&gt;&lt;u&gt;boot device&lt;/u&gt;&lt;/em&gt; (~MicroSD Card, USB) on each supported platform.&lt;/li&gt;
  &lt;li&gt;Not all Partiotions are really required.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.nvidia.com/jetson/l4t/Tegra%20Linux%20Driver%20Package%20Development%20Guide/part_config.html#wwp115285&quot;&gt;Jetson Nano Development Module (P3448-0000) Flashed to On-Board Memory&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.nvidia.com/jetson/l4t/Tegra%20Linux%20Driver%20Package%20Development%20Guide/part_config.html#wwp116068&quot;&gt;Jetson Nano Development Module (P3448-0000) Flashed to Micro SD Card&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.nvidia.com/jetson/l4t/Tegra%20Linux%20Driver%20Package%20Development%20Guide/part_config.html#wwp117730&quot;&gt;Jetson Nano Production Module (P3448-0002)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bootloader-update&quot;&gt;Bootloader Update&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;NVIDIA® Jetson™ Nano platform use the &lt;strong&gt;&lt;em&gt;Debian package&lt;/em&gt;&lt;/strong&gt; facility to update Bootloader.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Dual Boot Strategy&lt;/em&gt;&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;&lt;u&gt;Ensures that a usable Bootloader partition exists at all times during an update&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;bootloader-components-validation--partition-layout&quot;&gt;Bootloader Components Validation &amp;amp; Partition Layout&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Boot Configuration Table&lt;/strong&gt; (BCT) is stored in a partition named BCT.&lt;/li&gt;
  &lt;li&gt;The NVIDIA flashing utility &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tegraflash.py&lt;/code&gt; writes up to &lt;em&gt;&lt;u&gt;64 instances of the BCT&lt;/u&gt;&lt;/em&gt;.
    &lt;h4 id=&quot;bootloader-validation&quot;&gt;&lt;em&gt;&lt;u&gt;Bootloader Validation&lt;/u&gt;&lt;/em&gt;:&lt;/h4&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;BootROM&lt;/strong&gt; validates the BCT through an &lt;em&gt;&lt;u&gt;integrated checksum&lt;/u&gt;&lt;/em&gt; or &lt;em&gt;&lt;u&gt;RSA signature&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;If the calculated checksum or signature does not match the value in the BCT located at the beginning of the partition, the BootROM attempts to validate the next instances of the BCT.&lt;/li&gt;
  &lt;li&gt;When &lt;strong&gt;BootROM&lt;/strong&gt; finds a valid set of checksums or signatures, it transfers control to the specified instance of TegraBoot.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TegraBoot&lt;/strong&gt; computes and &lt;em&gt;&lt;u&gt;validates the checksums&lt;/u&gt;&lt;/em&gt; for the first &lt;strong&gt;BFS&lt;/strong&gt; and the first &lt;strong&gt;KFS&lt;/strong&gt; and the signatures the individual files. When the checksums and signatures have been validated, TegraBoot loads the appropriate boot files,
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;BFS&lt;/strong&gt;: a set of all of the files in a group of partitions that are concerned with booting.
        &lt;ul&gt;
          &lt;li&gt;The TegraBoot CPU binary&lt;/li&gt;
          &lt;li&gt;DTB files used by Bootloader&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;KFS&lt;/strong&gt;: a set of all of the files in a group of partitions that are concerned with loading the kernel.
        &lt;ul&gt;
          &lt;li&gt;DTB files used by the kernel&lt;/li&gt;
          &lt;li&gt;Warmboot binary&lt;/li&gt;
          &lt;li&gt;Trusted OS image&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;After validation, TegraBoot transfers control to the boot loader, e.g. &lt;strong&gt;CBoot&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;The CBoot loader validates and loads the next-level software component, such as the &lt;strong&gt;Linux kernel&lt;/strong&gt; or &lt;strong&gt;U‑Boot&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;If TegraBoot &lt;em&gt;&lt;u&gt;fails to validate&lt;/u&gt;&lt;/em&gt; the first BFS andKFS, it &lt;em&gt;&lt;u&gt;overwrites itself&lt;/u&gt;&lt;/em&gt; and &lt;em&gt;&lt;u&gt;resets the board&lt;/u&gt;&lt;/em&gt; so that the BootROM can validate and load the next set of TegraBoot, BFS, and KFS.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;partition-layout&quot;&gt;&lt;em&gt;&lt;u&gt;Partition Layout&lt;/u&gt;&lt;/em&gt;:&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;&lt;u&gt;Boot Partition&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;BCT&lt;/strong&gt;, which contains redundant instances of the &lt;em&gt;&lt;u&gt;Boot Configuration Table&lt;/u&gt;&lt;/em&gt;. This must be the first partition on the boot device.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;NVC&lt;/strong&gt; contains &lt;em&gt;&lt;u&gt;TegraBoot&lt;/u&gt;&lt;/em&gt;. This must be the second boot partition.&lt;/li&gt;
  &lt;li&gt;The following boot partitions, PT through BPF, are part of the BFS.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;PT&lt;/strong&gt; contains layout information for each BFS, and indicates the beginning of each one. It is the first partition in the BFS.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TBC&lt;/strong&gt; contains the &lt;em&gt;&lt;u&gt;TegraBoot CPU-side binary&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;RP1&lt;/strong&gt; contains &lt;em&gt;&lt;u&gt;TegraBoot DTBs&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;EBT&lt;/strong&gt; contains &lt;em&gt;&lt;u&gt;CBoot&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;WB0&lt;/strong&gt; contains the &lt;em&gt;&lt;u&gt;warm boot binary&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;BPF&lt;/strong&gt; contains &lt;a href=&quot;/_post/embedded/linux/boot_process/jetson_nano#jetson-nano-bootloader-functionalities&quot;&gt;&lt;em&gt;&lt;u&gt;BPMP microcode&lt;/u&gt;&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;NVC‑1&lt;/strong&gt; contains a copy of NVC.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;PT‑1&lt;/strong&gt; through BPF‑1 are copy partitions for the primaries NVC through BPF, making up a copy of the BFS, denoted BFS‑1.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;PAD&lt;/strong&gt; is an &lt;em&gt;&lt;u&gt;empty partition&lt;/u&gt;&lt;/em&gt; which ensures the VER and VER_b are at the very end of the boot partition.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;VER_b&lt;/strong&gt; contains additional &lt;em&gt;&lt;u&gt;version information for redundancy and version checking&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;VER&lt;/strong&gt; contains version information.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;&lt;u&gt;GP1&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt; contains the sdmmc_user device’s &lt;em&gt;&lt;u&gt;primary GPT&lt;/u&gt;&lt;/em&gt;. All partitions defined after this one are configured in the Linux kernel, and are accessible by standard partition tools such as gdisk and parted.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;&lt;u&gt;User Partition&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The following partitions constitute the kernel-file-set (KFS), and have redundant copy partitions:&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;DTB&lt;/strong&gt; contains &lt;em&gt;&lt;u&gt;kernel DTBs&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TOS&lt;/strong&gt; contains the &lt;em&gt;&lt;u&gt;trusted OS binary&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;EKS&lt;/strong&gt; is optional, and is reserved for future use.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;LNX&lt;/strong&gt; contains either the &lt;em&gt;&lt;u&gt;Linux kernel&lt;/u&gt;&lt;/em&gt; or &lt;em&gt;&lt;u&gt;U-Boot&lt;/u&gt;&lt;/em&gt;, depending on your choice of DFLT_KERNEL_IMAGE in the configuration file.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;DTB‑1&lt;/strong&gt; through EKS‑1 constitute a copy of the primary KFS, denoted KFS‑1.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;bootloader-update-payload-bup&quot;&gt;Bootloader Update Payload (BUP)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;multi-spec BUP&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;A multi-spec BUP includes multiple firmware binaries and BCT images of each type.&lt;/li&gt;
      &lt;li&gt;When you run the updater, it uses the appropriate binary of each type for the device you are updating.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;single-spec BUP&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;A single-spec BUP contains just one binary of each type, and can be used to update just one Jetson device configuration.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Detailed Steps for:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.nvidia.com/jetson/l4t/Tegra%20Linux%20Driver%20Package%20Development%20Guide/bootloader_update_nano_tx1.html#wwpID0E0IG0HA&quot;&gt;Generating the Bootloader Update Payload (BUP)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.nvidia.com/jetson/l4t/Tegra%20Linux%20Driver%20Package%20Development%20Guide/bootloader_update_nano_tx1.html#wwpID0E03E0HA&quot;&gt;Bootloader Update&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.nvidia.com/jetson/l4t/Tegra%20Linux%20Driver%20Package%20Development%20Guide/bootloader_update_nano_tx1.html#wwpID0E0QE0HA&quot;&gt;Bootloader Update Flow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;references&quot;&gt;References:&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=DV5S_ZSdK0s&amp;amp;t=6s&amp;amp;ab_channel=PentesterAcademyTV&quot;&gt;Embedded Linux Booting Process (Multi-Stage Bootloaders, Kernel, Filesystem)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Akhilesh Moghe</name></author><category term="Linux" /><category term="Embedded Linux" /><category term="Bootloader" /><category term="Jetson Nano" /><category term="Linux" /><category term="Embedded Linux" /><category term="Bootloader" /><category term="Jetson Nano" /><summary type="html">Jetson Nano Bootloader functionalities: The primary function of the NVIDIA® Jetson Nano™ boot software is to initialize the SoC (System on a Chip), including: Initializing MC/EMC/CPU Setting up security parameters Loading different firmware Maintaining Chain of Trust Setting memory carveouts for different firmware Flashing the device Booting to the operating system Additionally, the Jetson Nano boot software also performs other operations defined by product requirements, including but not limited to: Initialization of HDMI™/DSI Displaying the boot logo BPMP??? BPMP is NVIDIA Tegra Boot and Power Management Processor The BPMP is a specific processor in Tegra chip, which is designed for booting process handling and offloading the power management, clock management, and reset control tasks from the CPU. The BPMP firmware driver, which can create the interprocessor communication (IPC) between the CPU and BPMP. Bootloader Components 0. BootROM Jetson Nano BootROM (BR) is hard-wired in the SoC. It initializes the Boot Media and loads bootloaders and firmware from the Boot Media. Boot Configuration Table (BCT) Multiple copies of the BootROM Boot Configuration Table (BCT) may be stored at the start of the Boot-Media. The BCT contains configuration parameters used by the BootROM for hardware initialization. Bootloader info in BCT: Size Entry point Load address Hash 1. TegraBoot TegraBoot (NVTBoot) is the first boot software component loaded by BootROM in SysRAM (Internal RAM), and runs on BPMP. 2 Types: One used for cold boot (~hard boot:restart the board) One for recovery boot/flashing Responsibilities: Loading and initializing firmware (FW) components such as TOS TOS contains the trusted OS binary. Creating carveouts carveouts: It’s share memory for the coprocess. Completing CPU initialization Loading the next stage bootloader Supporting flashing Supporting RCM boot Recovery mode: used during flasing the board Reading PMIC reset reason PMIC: Power Management IC Loading the bootloader device tree and passing the device tree load address to CBoot Stops execution when the CCPLEX is booted CCPLEX: main CPU Complex, CCPLEX typically runs the system’s primary software stack. 2. TegrBoot CPU Add rollback prevention. Using bootloader DTB(~device tree binary), perform EMC(~Electromagnetic Compatibility) training and update kernel DTB with training results. Pass control to CBoot. 3. CBoot Primary CPU bootloader used on mobile platforms in the cold boot path. features: Supports display and boot logo/bmp splash Based on the Little Kernel (LK) open source bootloader Uses the interrupt and scheduling frameworks of LK Uses CDF for frameworks, drivers, and libraries BootLoader and kernel use separate device trees stored in separate partitions. Responsibilities: Parsing the CPU-BL parameters and initializing the bootloader device tree Chaining to U-Boot to boot the kernel Supporting the update mechanism Unhalts the BPMP so that the BPMP-FW can start running 4. U-Boot default OS bootloader for NVIDIA® Jetson™ L4T Driver Package. Partitions L4T supports formatting mass storage media(~SD cards, USB) into multiple partitions for storing data, such as the device OS image, Bootloader image, device firmware, and Bootloader splash screens. Partition Configuration file Located at &amp;lt;top&amp;gt;/Linux_for_Tegra/bootloader/t210ref/cfg/ for Jetson Nano devices NVIDIA Jetson Nano (SKU 0000): flash_l4t_t210_max-spi_sd_p3448.xml NVIDIA Jetson Nano (SKU 0002): flash_l4t_t210_emmc_p3448.xml During the flashing procedure, flash.sh reads in the partition configuration file, translates keywords into values specified in &amp;lt;device&amp;gt;.conf or in option parameters and saves the data in bootloader/flash.xml. Then __*bootloader/tegraflash.py*__ reads in bootloader/flash.xml and performs actual flashing as specified by bootloader/flash.xml. Partition Table Overview Describe partition use for the boot device (~MicroSD Card, USB) on each supported platform. Not all Partiotions are really required. Jetson Nano Development Module (P3448-0000) Flashed to On-Board Memory Jetson Nano Development Module (P3448-0000) Flashed to Micro SD Card Jetson Nano Production Module (P3448-0002) Bootloader Update NVIDIA® Jetson™ Nano platform use the Debian package facility to update Bootloader. Dual Boot Strategy Ensures that a usable Bootloader partition exists at all times during an update. Bootloader Components Validation &amp;amp; Partition Layout Boot Configuration Table (BCT) is stored in a partition named BCT. The NVIDIA flashing utility tegraflash.py writes up to 64 instances of the BCT. Bootloader Validation: BootROM validates the BCT through an integrated checksum or RSA signature. If the calculated checksum or signature does not match the value in the BCT located at the beginning of the partition, the BootROM attempts to validate the next instances of the BCT. When BootROM finds a valid set of checksums or signatures, it transfers control to the specified instance of TegraBoot. TegraBoot computes and validates the checksums for the first BFS and the first KFS and the signatures the individual files. When the checksums and signatures have been validated, TegraBoot loads the appropriate boot files, BFS: a set of all of the files in a group of partitions that are concerned with booting. The TegraBoot CPU binary DTB files used by Bootloader KFS: a set of all of the files in a group of partitions that are concerned with loading the kernel. DTB files used by the kernel Warmboot binary Trusted OS image After validation, TegraBoot transfers control to the boot loader, e.g. CBoot. The CBoot loader validates and loads the next-level software component, such as the Linux kernel or U‑Boot. If TegraBoot fails to validate the first BFS andKFS, it overwrites itself and resets the board so that the BootROM can validate and load the next set of TegraBoot, BFS, and KFS. Partition Layout: 1. Boot Partition: BCT, which contains redundant instances of the Boot Configuration Table. This must be the first partition on the boot device. NVC contains TegraBoot. This must be the second boot partition. The following boot partitions, PT through BPF, are part of the BFS. PT contains layout information for each BFS, and indicates the beginning of each one. It is the first partition in the BFS. TBC contains the TegraBoot CPU-side binary. RP1 contains TegraBoot DTBs. EBT contains CBoot. WB0 contains the warm boot binary. BPF contains BPMP microcode NVC‑1 contains a copy of NVC. PT‑1 through BPF‑1 are copy partitions for the primaries NVC through BPF, making up a copy of the BFS, denoted BFS‑1. PAD is an empty partition which ensures the VER and VER_b are at the very end of the boot partition. VER_b contains additional version information for redundancy and version checking. VER contains version information. 2. GP1 contains the sdmmc_user device’s primary GPT. All partitions defined after this one are configured in the Linux kernel, and are accessible by standard partition tools such as gdisk and parted. 3. User Partition: The following partitions constitute the kernel-file-set (KFS), and have redundant copy partitions: DTB contains kernel DTBs. TOS contains the trusted OS binary. EKS is optional, and is reserved for future use. LNX contains either the Linux kernel or U-Boot, depending on your choice of DFLT_KERNEL_IMAGE in the configuration file. DTB‑1 through EKS‑1 constitute a copy of the primary KFS, denoted KFS‑1. Bootloader Update Payload (BUP) multi-spec BUP: A multi-spec BUP includes multiple firmware binaries and BCT images of each type. When you run the updater, it uses the appropriate binary of each type for the device you are updating. single-spec BUP: A single-spec BUP contains just one binary of each type, and can be used to update just one Jetson device configuration. Detailed Steps for: Generating the Bootloader Update Payload (BUP) Bootloader Update Bootloader Update Flow References: Embedded Linux Booting Process (Multi-Stage Bootloaders, Kernel, Filesystem)</summary></entry><entry><title type="html">Design Patterns: Most Important GRASP Patterns of designing an application or module</title><link href="http://localhost:4000/c++/design%20patterns/2021/12/07/C++_Design_Patterns_GRASP_Patterns.html" rel="alternate" type="text/html" title="Design Patterns: Most Important GRASP Patterns of designing an application or module" /><published>2021-12-07T05:33:22+05:30</published><updated>2021-12-07T05:33:22+05:30</updated><id>http://localhost:4000/c++/design%20patterns/2021/12/07/C++_Design_Patterns_GRASP_Patterns</id><content type="html" xml:base="http://localhost:4000/c++/design%20patterns/2021/12/07/C++_Design_Patterns_GRASP_Patterns.html">&lt;p&gt;This write-up will explain different &lt;strong&gt;&lt;em&gt;&lt;u&gt;GRASP Patterns&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt;, explained in book: &lt;a href=&quot;https://www.amazon.com/gp/product/0131489062/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;amp;tag=fluentcpp-20&amp;amp;creative=9325&amp;amp;linkCode=as2&amp;amp;creativeASIN=0131489062&amp;amp;linkId=43cfc4d0a6ea922ef663317e4f91db85&quot;&gt;Applying UML and Patterns&lt;/a&gt;, which are more important in day to day programming life than the whole lot of GoF design patterns.
GRASP is a set of 9 fundamental principles in OOPs design and responsibility assignment.
These patterns solve some software problem common to many software development projects.&lt;/p&gt;

&lt;h2 id=&quot;information-expert-information-hiding&quot;&gt;Information Expert (Information Hiding)&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;&lt;u&gt;Problem&lt;/u&gt;&lt;/em&gt; it solves: How will you assign a responsibility to a module/class?&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;&lt;u&gt;Solution&lt;/u&gt;&lt;/em&gt;: Assign responsibility to the class that has the information needed to fulfill it.&lt;/li&gt;
  &lt;li&gt;Used to determine where to delegate responsibilities such as methods, computed fields, and so on.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;&lt;u&gt;If you have an operation to do, and this operations needs inputs, then you should consider putting the responsibility of carrying out this operation in the class that contains the inputs for it&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Helps keeping the data local, i.e. &lt;strong&gt;&lt;em&gt;Data Encapsulation&lt;/em&gt;&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;Reduces relationships between the classes. (Class is self-sufficient in terms of data to carryout it’s tasks.)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;creator&quot;&gt;Creator&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;The creation of objects is one of the most common activities in an object-oriented system.&lt;/li&gt;
  &lt;li&gt;Which class is responsible for creating objects is a fundamental property of the relationship between objects of particular classes.&lt;/li&gt;
  &lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;reference&quot;&gt;Reference&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cplusplus.com/reference/forward_list/forward_list/&quot;&gt;std::forward_list&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Akhilesh Moghe</name><email>akhileshmoghe@live.com</email></author><category term="C++" /><category term="Design Patterns" /><category term="C++" /><category term="Design Patterns" /><summary type="html">This write-up will explain different GRASP Patterns, explained in book: Applying UML and Patterns, which are more important in day to day programming life than the whole lot of GoF design patterns. GRASP is a set of 9 fundamental principles in OOPs design and responsibility assignment. These patterns solve some software problem common to many software development projects. Information Expert (Information Hiding) Problem it solves: How will you assign a responsibility to a module/class? Solution: Assign responsibility to the class that has the information needed to fulfill it. Used to determine where to delegate responsibilities such as methods, computed fields, and so on. If you have an operation to do, and this operations needs inputs, then you should consider putting the responsibility of carrying out this operation in the class that contains the inputs for it. Helps keeping the data local, i.e. Data Encapsulation. Reduces relationships between the classes. (Class is self-sufficient in terms of data to carryout it’s tasks.) Creator The creation of objects is one of the most common activities in an object-oriented system. Which class is responsible for creating objects is a fundamental property of the relationship between objects of particular classes. Reference std::forward_list</summary></entry><entry><title type="html">AWS IoT Twinmaker:</title><link href="http://localhost:4000/posts/twinmaker" rel="alternate" type="text/html" title="AWS IoT Twinmaker:" /><published>2021-12-07T00:00:00+05:30</published><updated>2021-12-07T00:00:00+05:30</updated><id>http://localhost:4000/posts/AWS-IoT-Twinmaker</id><content type="html" xml:base="http://localhost:4000/posts/twinmaker">&lt;p&gt;This write-up will focus on newly launched AWS IoT Twinmaker service.&lt;/p&gt;

&lt;h2 id=&quot;digital-twins&quot;&gt;Digital Twins&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Digital twins are &lt;em&gt;&lt;u&gt;virtual representations of physical systems&lt;/u&gt;&lt;/em&gt; such as buildings, factories, production lines, and equipment that are regularly updated with real-world data to mimic the &lt;strong&gt;structure&lt;/strong&gt;, &lt;strong&gt;state&lt;/strong&gt;, and &lt;strong&gt;behavior&lt;/strong&gt; of the systems they represent.&lt;/li&gt;
  &lt;li&gt;To create and use digital twins of real-world systems to monitor and optimize operations.&lt;/li&gt;
  &lt;li&gt;We can create digital twins of &lt;strong&gt;equipment&lt;/strong&gt;, &lt;strong&gt;processes&lt;/strong&gt;, and &lt;strong&gt;facilities&lt;/strong&gt; by connecting data from different data sources like &lt;em&gt;&lt;u&gt;equipment sensors&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;video feeds&lt;/u&gt;&lt;/em&gt;, and &lt;em&gt;&lt;u&gt;business applications&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;digital-twin-graph&quot;&gt;Digital Twin Graph&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;AWS IoT TwinMaker forms a digital twin graph that combines and understands the &lt;em&gt;&lt;u&gt;relationships between virtual representations of your physical systems and connected data sources&lt;/u&gt;&lt;/em&gt;, so you can accurately model your real-world environment.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;&lt;u&gt;Import&lt;/u&gt;&lt;/em&gt; existing &lt;strong&gt;3D models&lt;/strong&gt; (such as &lt;em&gt;&lt;u&gt;CAD files&lt;/u&gt;&lt;/em&gt;, and &lt;em&gt;&lt;u&gt;point cloud scans&lt;/u&gt;&lt;/em&gt;) to compose and arrange &lt;strong&gt;3D scenes&lt;/strong&gt; of a physical space and its contents (e.g. a factory and its equipment) using simple 3D tools.&lt;/li&gt;
  &lt;li&gt;We can add data to these models/scenes for visualization as:
    &lt;ul&gt;
      &lt;li&gt;Interactive video.&lt;/li&gt;
      &lt;li&gt;sensor data overlays from the connected data sources.&lt;/li&gt;
      &lt;li&gt;insights from connected machine learning (ML) and simulation services.&lt;/li&gt;
      &lt;li&gt;equipment maintenance records and manuals.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Using the digital twin graph, customers can now issue geospatial queries such as finding all cameras that are pointing to an equipment to help with root cause analysis.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;amazon-managed-grafana-plugin&quot;&gt;Amazon Managed Grafana plugin&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Can be used to create a web-based application for end users.&lt;/li&gt;
  &lt;li&gt;Use Grafana applications to observe and interact with the digital twin to help them optimize factory operations, increase production output, and improve equipment performance.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;model-builder&quot;&gt;Model Builder&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Allows you to create &lt;em&gt;&lt;u&gt;workspaces&lt;/u&gt;&lt;/em&gt; that will hold the resources, such as entity models and visual assets needed to create a digital twin.&lt;/li&gt;
  &lt;li&gt;In this workspace, create entities that represent digital replicas of your equipment.&lt;/li&gt;
  &lt;li&gt;Specify custom relationships between these entities to create a digital twin graph of your real-world system.&lt;/li&gt;
  &lt;li&gt;Using the digital twin graph, customers can now issue geospatial queries such as finding all cameras that are pointing to an equipment to help with root cause analysis.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-connector&quot;&gt;Data Connector&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Associate entities with connectors (called as &lt;em&gt;components&lt;/em&gt; in AWS IoT TwinMaker) to data stores such as AWS IoT SiteWise, to provide context to the data present in various data stores.&lt;/li&gt;
  &lt;li&gt;Built-in &lt;strong&gt;&lt;em&gt;&lt;u&gt;Data Connectors&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt; for the following AWS services:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;AWS IoT SiteWise&lt;/strong&gt; for equipment and &lt;em&gt;&lt;u&gt;time-series sensor data&lt;/u&gt;&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Amazon Kinesis Video Streams&lt;/strong&gt; for &lt;em&gt;&lt;u&gt;video data&lt;/u&gt;&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Amazon Simple Storage Service (S3)&lt;/strong&gt; for &lt;em&gt;&lt;u&gt;storage of visual resources&lt;/u&gt;&lt;/em&gt; (for example, CAD files) and data from business applications.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Provides a framework for you to create &lt;em&gt;&lt;u&gt;your own Data Connectors&lt;/u&gt;&lt;/em&gt; to use with other data sources (such as &lt;a href=&quot;https://www.snowflake.com/&quot;&gt;Snowflake&lt;/a&gt; and &lt;a href=&quot;https://siemens.mindsphere.io/en&quot;&gt;Siemens MindSphere&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;scene-composer&quot;&gt;Scene Composer&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;A tool to create visualizations in 3D.&lt;/li&gt;
  &lt;li&gt;You can bring previously built 3D/CAD models into your resource library in Amazon S3.&lt;/li&gt;
  &lt;li&gt;these visual assets can be brought into a scene, and position the 3D assets to match your real-world systems.&lt;/li&gt;
  &lt;li&gt;visual annotations such as tags on top of the base scene.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;references&quot;&gt;References&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/blogs/iot/introducing-aws-iot-twinmaker/&quot;&gt;Introducing AWS IoT TwinMaker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;further-reference&quot;&gt;Further Reference&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/aws-samples/aws-iot-twinmaker-samples&quot;&gt;aws-samples/aws-iot-twinmaker-samples&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Akhilesh Moghe</name></author><category term="AWS IoT" /><category term="Digital Twin" /><category term="AWS IoT" /><category term="Digital Twin" /><summary type="html">This write-up will focus on newly launched AWS IoT Twinmaker service. Digital Twins Digital twins are virtual representations of physical systems such as buildings, factories, production lines, and equipment that are regularly updated with real-world data to mimic the structure, state, and behavior of the systems they represent. To create and use digital twins of real-world systems to monitor and optimize operations. We can create digital twins of equipment, processes, and facilities by connecting data from different data sources like equipment sensors, video feeds, and business applications. Digital Twin Graph AWS IoT TwinMaker forms a digital twin graph that combines and understands the relationships between virtual representations of your physical systems and connected data sources, so you can accurately model your real-world environment. Import existing 3D models (such as CAD files, and point cloud scans) to compose and arrange 3D scenes of a physical space and its contents (e.g. a factory and its equipment) using simple 3D tools. We can add data to these models/scenes for visualization as: Interactive video. sensor data overlays from the connected data sources. insights from connected machine learning (ML) and simulation services. equipment maintenance records and manuals. Using the digital twin graph, customers can now issue geospatial queries such as finding all cameras that are pointing to an equipment to help with root cause analysis. Amazon Managed Grafana plugin Can be used to create a web-based application for end users. Use Grafana applications to observe and interact with the digital twin to help them optimize factory operations, increase production output, and improve equipment performance. Model Builder Allows you to create workspaces that will hold the resources, such as entity models and visual assets needed to create a digital twin. In this workspace, create entities that represent digital replicas of your equipment. Specify custom relationships between these entities to create a digital twin graph of your real-world system. Using the digital twin graph, customers can now issue geospatial queries such as finding all cameras that are pointing to an equipment to help with root cause analysis. Data Connector Associate entities with connectors (called as components in AWS IoT TwinMaker) to data stores such as AWS IoT SiteWise, to provide context to the data present in various data stores. Built-in Data Connectors for the following AWS services: AWS IoT SiteWise for equipment and time-series sensor data Amazon Kinesis Video Streams for video data Amazon Simple Storage Service (S3) for storage of visual resources (for example, CAD files) and data from business applications. Provides a framework for you to create your own Data Connectors to use with other data sources (such as Snowflake and Siemens MindSphere). Scene Composer A tool to create visualizations in 3D. You can bring previously built 3D/CAD models into your resource library in Amazon S3. these visual assets can be brought into a scene, and position the 3D assets to match your real-world systems. visual annotations such as tags on top of the base scene. References Introducing AWS IoT TwinMaker Further Reference aws-samples/aws-iot-twinmaker-samples</summary></entry><entry><title type="html">How to limit a process to run on One CPU core in Linux</title><link href="http://localhost:4000/linux/systems%20engineering/os/2021/12/06/How-to-run-a-process-on-a-particular-cpu-core.html" rel="alternate" type="text/html" title="How to limit a process to run on One CPU core in Linux" /><published>2021-12-06T12:33:22+05:30</published><updated>2021-12-06T12:33:22+05:30</updated><id>http://localhost:4000/linux/systems%20engineering/os/2021/12/06/How-to-run-a-process-on-a-particular-cpu-core</id><content type="html" xml:base="http://localhost:4000/linux/systems%20engineering/os/2021/12/06/How-to-run-a-process-on-a-particular-cpu-core.html">&lt;p&gt;This write-up explains different ways to restrict a program to run on a specific CPU core(s). This might be required for some high priority tasks/programs to run dedicatedly on few core on a multi-core/processor systems. This is used to achieve performance benefits from multi-processor systems.&lt;/p&gt;

&lt;h2 id=&quot;sched-setaffinity&quot;&gt;sched-setaffinity()&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Linux System Call&lt;/li&gt;
  &lt;li&gt;A process’s CPU &lt;strong&gt;&lt;em&gt;affinity mask&lt;/em&gt;&lt;/strong&gt; determines the &lt;em&gt;&lt;u&gt;set of CPUs on which it is eligible to run&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Dedicating one CPU to a particular process can be acheved as:
    &lt;ul&gt;
      &lt;li&gt;setting the affinity mask of that process to specify a single CPU.&lt;/li&gt;
      &lt;li&gt;and setting the affinity mask of all other processes to exclude that CPU.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;em&gt;&lt;u&gt;Restricting a process to run on a single CPU also avoids the performance cost caused by the cache invalidation that occurs when a process ceases to execute on one CPU and then recommences execution on a different CPU&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;These restrictions on the actual set of CPUs on which the process will run are silently imposed by the kernel.&lt;/li&gt;
  &lt;li&gt;The affinity mask is actually a per-thread attribute that can be adjusted independently for each of the threads in a thread group.
    &lt;ul&gt;
      &lt;li&gt;use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-a&lt;/code&gt; option with &lt;strong&gt;&lt;em&gt;taskset&lt;/em&gt;&lt;/strong&gt; command to add affinity mask to all threads of the process.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;A child created via fork(2) inherits its parent’s CPU affinity mask. The affinity mask is preserved across an execve(2).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;python-3-sched_setaffinity&quot;&gt;Python 3: sched_setaffinity()&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Python 3 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;os module&lt;/code&gt; supports sched-setaffinity() method&lt;/li&gt;
  &lt;li&gt;Example usage:
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import os
&amp;gt;&amp;gt;&amp;gt; os.sched_getaffinity(0)
{0, 1, 2, 3}
----------------

&amp;gt;&amp;gt;&amp;gt; os.sched_setaffinity(0, {1, 3})
&amp;gt;&amp;gt;&amp;gt; os.sched_getaffinity(0)
{1, 3}
----------------

&amp;gt;&amp;gt;&amp;gt; x = {i for i in range(10)}
&amp;gt;&amp;gt;&amp;gt; x
{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}
----------------

&amp;gt;&amp;gt;&amp;gt; os.sched_setaffinity(0, x)
&amp;gt;&amp;gt;&amp;gt; os.sched_getaffinity(0)
{0, 1, 2, 3}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;reference&quot;&gt;Reference&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://linux.die.net/man/2/sched_setaffinity&quot;&gt;sched_setaffinity(2)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.python.org/dev/library/os.html#os.sched_setaffinity&quot;&gt;Python 3: sched_setaffinity()&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/15639779/why-does-multiprocessing-use-only-a-single-core-after-i-import-numpy&quot;&gt;Why does multiprocessing use only a single core after I import numpy?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;taskset&quot;&gt;taskset&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Linux Command&lt;/li&gt;
  &lt;li&gt;set or retrieve a process’s &lt;strong&gt;*&lt;u&gt;CPU affinity*&lt;/u&gt;&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;Works on a running process and can also launch a new process.&lt;/li&gt;
  &lt;li&gt;CPU affinity is a scheduler property that “bonds” a process to a given set of CPUs on the system.&lt;/li&gt;
  &lt;li&gt;The Linux scheduler will honor the given CPU affinity and the process will not run on any other CPUs.&lt;/li&gt;
  &lt;li&gt;:warning: Note that the Linux scheduler also supports natural CPU affinity:
    &lt;ul&gt;
      &lt;li&gt;the scheduler attempts to keep processes on the same CPU as long as practical for performance reasons.&lt;/li&gt;
      &lt;li&gt;Therefore, forcing a specific CPU affinity is useful only in certain applications.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The CPU affinity is represented as a &lt;strong&gt;bitmask&lt;/strong&gt;,
    &lt;ul&gt;
      &lt;li&gt;with the lowest order bit corresponding to the first logical CPU.&lt;/li&gt;
      &lt;li&gt;and the highest order bit corresponding to the last logical CPU.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;:memo: Not all CPUs may exist on a given system but a mask may specify more CPUs than are present.&lt;/li&gt;
  &lt;li&gt;:memo: A retrieved mask will reflect only the bits that correspond to CPUs physically on the system.&lt;/li&gt;
  &lt;li&gt;Examples:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  taskset -c 0 mycommand --option    # start a command with the given affinity.
  -------------------

  taskset -c -pa 0 1234              # set the affinity of a running process.
                                     # -a for applying affinity mask to all the threads of the process.
  -------------------

  0x00000001
     is processor #0,
  -------------------

  0x00000003
     is processors #0 and #1,
  -------------------

  0xFFFFFFFF
     is processors #0 through #31,
  -------------------

  32
     is processors #1, #4, and #5,
  -------------------

  --cpu-list 0-2,6
  or
  - c 0-2,6
     is processors #0, #1, #2, and #6.
  -------------------

  --cpu-list 0-10:2
  or
  -c 0-10:2
     is processors #0, #2, #4, #6, #8 and #10. The suffix &quot;:N&quot;
     specifies stride in the range, for example 0-10:3 is
     interpreted as 0,3,6,9 list.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;reference-1&quot;&gt;Reference&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://man7.org/linux/man-pages/man1/taskset.1.html&quot;&gt;taskset&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reference-2&quot;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://unix.stackexchange.com/questions/23106/how-to-limit-a-process-to-one-cpu-core-in-linux&quot;&gt;How to limit a process to one CPU core in Linux?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Akhilesh Moghe</name></author><category term="Linux" /><category term="Systems Engineering" /><category term="OS" /><category term="Linux" /><category term="Systems Engineering" /><category term="OS" /><summary type="html">This write-up explains different ways to restrict a program to run on a specific CPU core(s). This might be required for some high priority tasks/programs to run dedicatedly on few core on a multi-core/processor systems. This is used to achieve performance benefits from multi-processor systems. sched-setaffinity() Linux System Call A process’s CPU affinity mask determines the set of CPUs on which it is eligible to run. Dedicating one CPU to a particular process can be acheved as: setting the affinity mask of that process to specify a single CPU. and setting the affinity mask of all other processes to exclude that CPU. Restricting a process to run on a single CPU also avoids the performance cost caused by the cache invalidation that occurs when a process ceases to execute on one CPU and then recommences execution on a different CPU. These restrictions on the actual set of CPUs on which the process will run are silently imposed by the kernel. The affinity mask is actually a per-thread attribute that can be adjusted independently for each of the threads in a thread group. use -a option with taskset command to add affinity mask to all threads of the process. A child created via fork(2) inherits its parent’s CPU affinity mask. The affinity mask is preserved across an execve(2). Python 3: sched_setaffinity() Python 3 os module supports sched-setaffinity() method Example usage: &amp;gt;&amp;gt;&amp;gt; import os &amp;gt;&amp;gt;&amp;gt; os.sched_getaffinity(0) {0, 1, 2, 3} ---------------- &amp;gt;&amp;gt;&amp;gt; os.sched_setaffinity(0, {1, 3}) &amp;gt;&amp;gt;&amp;gt; os.sched_getaffinity(0) {1, 3} ---------------- &amp;gt;&amp;gt;&amp;gt; x = {i for i in range(10)} &amp;gt;&amp;gt;&amp;gt; x {0, 1, 2, 3, 4, 5, 6, 7, 8, 9} ---------------- &amp;gt;&amp;gt;&amp;gt; os.sched_setaffinity(0, x) &amp;gt;&amp;gt;&amp;gt; os.sched_getaffinity(0) {0, 1, 2, 3} Reference sched_setaffinity(2) Python 3: sched_setaffinity() Why does multiprocessing use only a single core after I import numpy? taskset Linux Command set or retrieve a process’s *CPU affinity*. Works on a running process and can also launch a new process. CPU affinity is a scheduler property that “bonds” a process to a given set of CPUs on the system. The Linux scheduler will honor the given CPU affinity and the process will not run on any other CPUs. :warning: Note that the Linux scheduler also supports natural CPU affinity: the scheduler attempts to keep processes on the same CPU as long as practical for performance reasons. Therefore, forcing a specific CPU affinity is useful only in certain applications. The CPU affinity is represented as a bitmask, with the lowest order bit corresponding to the first logical CPU. and the highest order bit corresponding to the last logical CPU. :memo: Not all CPUs may exist on a given system but a mask may specify more CPUs than are present. :memo: A retrieved mask will reflect only the bits that correspond to CPUs physically on the system. Examples: taskset -c 0 mycommand --option # start a command with the given affinity. ------------------- taskset -c -pa 0 1234 # set the affinity of a running process. # -a for applying affinity mask to all the threads of the process. ------------------- 0x00000001 is processor #0, ------------------- 0x00000003 is processors #0 and #1, ------------------- 0xFFFFFFFF is processors #0 through #31, ------------------- 32 is processors #1, #4, and #5, ------------------- --cpu-list 0-2,6 or - c 0-2,6 is processors #0, #1, #2, and #6. ------------------- --cpu-list 0-10:2 or -c 0-10:2 is processors #0, #2, #4, #6, #8 and #10. The suffix &quot;:N&quot; specifies stride in the range, for example 0-10:3 is interpreted as 0,3,6,9 list. Reference taskset Reference How to limit a process to one CPU core in Linux?</summary></entry><entry><title type="html">5G: Private 5G Networks for IoT Use cases</title><link href="http://localhost:4000/5g/iot/edge%20computing/aws%20iot/2021/12/04/Private-5G-Networks.html" rel="alternate" type="text/html" title="5G: Private 5G Networks for IoT Use cases" /><published>2021-12-04T12:33:22+05:30</published><updated>2021-12-04T12:33:22+05:30</updated><id>http://localhost:4000/5g/iot/edge%20computing/aws%20iot/2021/12/04/Private-5G-Networks</id><content type="html" xml:base="http://localhost:4000/5g/iot/edge%20computing/aws%20iot/2021/12/04/Private-5G-Networks.html">&lt;p&gt;This write-up explains different use cases of Private 5G Networks, specifically in IoT &amp;amp; Edge-Computing domains.&lt;/p&gt;

&lt;h2 id=&quot;problems-with-existing-enterprise-networks&quot;&gt;Problems with existing Enterprise Networks&lt;/h2&gt;
&lt;p&gt;Enterprise networks are under strain, because:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Increasing internet connected-serving applications.&lt;/li&gt;
  &lt;li&gt;Increasing number of users.&lt;/li&gt;
  &lt;li&gt;Increasing number of Connected IoT Devices.&lt;/li&gt;
  &lt;li&gt;Increased Video content consumption.&lt;/li&gt;
  &lt;li&gt;Low Latency requirements.&lt;/li&gt;
  &lt;li&gt;Wired networks are inflexible and expensive to expand&lt;/li&gt;
  &lt;li&gt;Wi-Fi networks suffer from Coverage, Reliability &amp;amp; Capacity issues.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;advantages-of-5g-networks&quot;&gt;Advantages of 5G Networks&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Reliable network connectivity for use cases that involve device mobility.&lt;/li&gt;
  &lt;li&gt;Longer range than Wi-Fi networks.&lt;/li&gt;
  &lt;li&gt;Better coverage, especially in industrial/hospital environments.&lt;/li&gt;
  &lt;li&gt;Low-latency connectivity for IoT-Edge applications.&lt;/li&gt;
  &lt;li&gt;Full enterprise control over users, devices, network utilization and data. Implement enterprise-specific network configuration and security policies.&lt;/li&gt;
  &lt;li&gt;Convenience of CBRS (Citizens Broadband Radio Service) in the US with no need to acquire spectrum licenses.(US specific)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;private-5g-use-cases&quot;&gt;Private 5G use-cases&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Indoor Scenarios such as Industrial Manufacturing Hub or Hospitals or Retail stores
    &lt;ul&gt;
      &lt;li&gt;Improved coverage and reliability close to wired networks with flexibility as Wi-Fi.&lt;/li&gt;
      &lt;li&gt;Connect autonomous mobile robots (AMRs), automated guided vehicles (AGVs), video surveillance systems.&lt;/li&gt;
      &lt;li&gt;Underground deployments, where cellular network is often difficult to reach, unreliable.
        &lt;ul&gt;
          &lt;li&gt;Mining sites can be a great scenario for connectivity to Iot Sensors, video surveillance.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Point-of-sale (PoS) transactions, video surveillance in Retail stores.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Outdoor Scenarios such as Transport Hubs
    &lt;ul&gt;
      &lt;li&gt;Increase range and penetration over Wi-Fi in shipping ports, airports, train and bus terminals.&lt;/li&gt;
      &lt;li&gt;Reliable connectivity for IoT sensor data for predictive maintenance, video feeds for safety, push-to-talk (PTT) applications for communications.&lt;/li&gt;
      &lt;li&gt;Remote Places where public network services are not available like Oil-Gas, Mining IIoT sites&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;On-premise IoT-Edge-AI-ML Analysis
    &lt;ul&gt;
      &lt;li&gt;Low latency use-cases can be a reality as in case of Internet of Medical things (IoMT).&lt;/li&gt;
      &lt;li&gt;Real-time AI-ML diagnosis on sensors, video data.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Large Images/Videos data analysis
    &lt;ul&gt;
      &lt;li&gt;As in case of Radiology scans or live video, or Raw image data, which are relatively large chunks of data.&lt;/li&gt;
      &lt;li&gt;with 5G low latency and dedicated network without the risk of channel interference, these loads can be transmitted in real-time and analysis be performed on it or it can be made available for remote monitoring or diagnosis services.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;AR-VR applications
    &lt;ul&gt;
      &lt;li&gt;with all of the promises of 5G networks such as Low Latency, dedicated bandwidth, AR/VR application experiances can be made production grade, deployed and simultaneously used by large gatherings.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;aws-private-5g&quot;&gt;AWS Private 5G&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;It simplifies the procurement, deployment, and installation process&lt;/li&gt;
  &lt;li&gt;Allowing customers to deploy their own 4G/LTE or 5G network.&lt;/li&gt;
  &lt;li&gt;In the US, AWS Private 5G uses CBRS (Citizens Broadband Radio Service), avoiding the need to procure spectrum licenses.&lt;/li&gt;
  &lt;li&gt;Integration with Spectrum Access System (SAS) for FCC regulation compliance are handled by AWS.&lt;/li&gt;
  &lt;li&gt;Delivers, provisions, and maintains all the preintegrated hardware, 5G Core and RAN software, and SIM cards.&lt;/li&gt;
  &lt;li&gt;Small cell radio units (RUs) are deployed on premises and the 5G Core (5GC) software runs either in an AWS Region or on premises using AWS managed infrastructure (AWS Outposts).&lt;/li&gt;
  &lt;li&gt;Setup Customized Bandwidths, Latency and Quality of Service (QoS) profiles for groups of devices and applications.&lt;/li&gt;
  &lt;li&gt;Pricing is based on Network Coverage and Capacity requirements, but not the number of connected devices.&lt;/li&gt;
  &lt;li&gt;Zero upfront charges for radio units, on-premises hardware, and SIMs. No installation charges or additional software licensing fees.&lt;/li&gt;
  &lt;li&gt;Provision a private cellular network of any size.&lt;/li&gt;
  &lt;li&gt;Expand coverage, and scale number of connected devices as needed.&lt;/li&gt;
  &lt;li&gt;AWS IAM integration to manage access between AWS services and devices in the network.
    &lt;ul&gt;
      &lt;li&gt;5G-powered SIM cards are treated as IAM resources.&lt;/li&gt;
      &lt;li&gt;Manage SIM control policies.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Amazon CloudWatch Monitoring
    &lt;ul&gt;
      &lt;li&gt;Query metrics for network status, connected APs or SIMs, uplink and downlink usage by user, device, network categories.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/private5g/&quot;&gt;AWS Private 5G&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Akhilesh Moghe</name></author><category term="5G" /><category term="IoT" /><category term="Edge Computing" /><category term="AWS IoT" /><category term="5G" /><category term="IoT" /><category term="Edge Computing" /><category term="AWS IoT" /><summary type="html">This write-up explains different use cases of Private 5G Networks, specifically in IoT &amp;amp; Edge-Computing domains. Problems with existing Enterprise Networks Enterprise networks are under strain, because: Increasing internet connected-serving applications. Increasing number of users. Increasing number of Connected IoT Devices. Increased Video content consumption. Low Latency requirements. Wired networks are inflexible and expensive to expand Wi-Fi networks suffer from Coverage, Reliability &amp;amp; Capacity issues. Advantages of 5G Networks Reliable network connectivity for use cases that involve device mobility. Longer range than Wi-Fi networks. Better coverage, especially in industrial/hospital environments. Low-latency connectivity for IoT-Edge applications. Full enterprise control over users, devices, network utilization and data. Implement enterprise-specific network configuration and security policies. Convenience of CBRS (Citizens Broadband Radio Service) in the US with no need to acquire spectrum licenses.(US specific) Private 5G use-cases Indoor Scenarios such as Industrial Manufacturing Hub or Hospitals or Retail stores Improved coverage and reliability close to wired networks with flexibility as Wi-Fi. Connect autonomous mobile robots (AMRs), automated guided vehicles (AGVs), video surveillance systems. Underground deployments, where cellular network is often difficult to reach, unreliable. Mining sites can be a great scenario for connectivity to Iot Sensors, video surveillance. Point-of-sale (PoS) transactions, video surveillance in Retail stores. Outdoor Scenarios such as Transport Hubs Increase range and penetration over Wi-Fi in shipping ports, airports, train and bus terminals. Reliable connectivity for IoT sensor data for predictive maintenance, video feeds for safety, push-to-talk (PTT) applications for communications. Remote Places where public network services are not available like Oil-Gas, Mining IIoT sites On-premise IoT-Edge-AI-ML Analysis Low latency use-cases can be a reality as in case of Internet of Medical things (IoMT). Real-time AI-ML diagnosis on sensors, video data. Large Images/Videos data analysis As in case of Radiology scans or live video, or Raw image data, which are relatively large chunks of data. with 5G low latency and dedicated network without the risk of channel interference, these loads can be transmitted in real-time and analysis be performed on it or it can be made available for remote monitoring or diagnosis services. AR-VR applications with all of the promises of 5G networks such as Low Latency, dedicated bandwidth, AR/VR application experiances can be made production grade, deployed and simultaneously used by large gatherings. AWS Private 5G It simplifies the procurement, deployment, and installation process Allowing customers to deploy their own 4G/LTE or 5G network. In the US, AWS Private 5G uses CBRS (Citizens Broadband Radio Service), avoiding the need to procure spectrum licenses. Integration with Spectrum Access System (SAS) for FCC regulation compliance are handled by AWS. Delivers, provisions, and maintains all the preintegrated hardware, 5G Core and RAN software, and SIM cards. Small cell radio units (RUs) are deployed on premises and the 5G Core (5GC) software runs either in an AWS Region or on premises using AWS managed infrastructure (AWS Outposts). Setup Customized Bandwidths, Latency and Quality of Service (QoS) profiles for groups of devices and applications. Pricing is based on Network Coverage and Capacity requirements, but not the number of connected devices. Zero upfront charges for radio units, on-premises hardware, and SIMs. No installation charges or additional software licensing fees. Provision a private cellular network of any size. Expand coverage, and scale number of connected devices as needed. AWS IAM integration to manage access between AWS services and devices in the network. 5G-powered SIM cards are treated as IAM resources. Manage SIM control policies. Amazon CloudWatch Monitoring Query metrics for network status, connected APs or SIMs, uplink and downlink usage by user, device, network categories. Reference AWS Private 5G</summary></entry><entry><title type="html">AWS Greengrass Service V2: a Service to build, deploy and manage IoT applications on Edge Devices</title><link href="http://localhost:4000/on-premise%20cloud/cloud/aws/edge%20iot/2021/11/12/AWS-Greengrass.html" rel="alternate" type="text/html" title="AWS Greengrass Service V2: a Service to build, deploy and manage IoT applications on Edge Devices" /><published>2021-11-12T12:33:22+05:30</published><updated>2021-11-12T12:33:22+05:30</updated><id>http://localhost:4000/on-premise%20cloud/cloud/aws/edge%20iot/2021/11/12/AWS-Greengrass</id><content type="html" xml:base="http://localhost:4000/on-premise%20cloud/cloud/aws/edge%20iot/2021/11/12/AWS-Greengrass.html">&lt;p&gt;This write-up will only focus on AWS Sagemaker ML service with respect to ML model deployment to Edge devices and Cloud.&lt;/p&gt;

&lt;h2 id=&quot;ml-inference-on-greengrass-devices&quot;&gt;ML Inference on Greengrass devices&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;ML models can be trained using &lt;strong&gt;&lt;em&gt;&lt;u&gt;AWS Sagemaker&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt; or custom ml trainining ways. Models are stored in &lt;strong&gt;&lt;em&gt;&lt;u&gt;AWS S3&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt; for deployment to Greengrass devices.&lt;/li&gt;
  &lt;li&gt;ML models are deployed as artifacts in your components to perform inference on your core devices.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ml-components&quot;&gt;ML Components&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;AWS provides following Machine Learning components that can be deployed to edge devices to perform Machine Learning Inference.&lt;/li&gt;
  &lt;li&gt;ML models can be trained using &lt;strong&gt;&lt;em&gt;&lt;u&gt;AWS Sagemaker&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt; or custom ml trainining ways. Models are stored in &lt;strong&gt;&lt;em&gt;&lt;u&gt;AWS S3&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt; for deployment to Greengrass devices.&lt;/li&gt;
  &lt;li&gt;AWS-provided machine learning components are broadly categorized as follows:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;Model component&lt;/em&gt;&lt;/strong&gt; — Contains machine learning models as &lt;em&gt;&lt;u&gt;Greengrass artifacts&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;Runtime component&lt;/em&gt;&lt;/strong&gt; — Contains the &lt;em&gt;&lt;u&gt;script&lt;/u&gt;&lt;/em&gt; that installs the machine learning framework and its dependencies on the Greengrass core device.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;Inference component&lt;/em&gt;&lt;/strong&gt; — Contains the &lt;em&gt;&lt;u&gt;inference code&lt;/u&gt;&lt;/em&gt; and includes &lt;em&gt;&lt;u&gt;component dependencies&lt;/u&gt;&lt;/em&gt; to install the machine learning framework and download pre-trained machine learning models.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;To perform custom machine learning inference with &lt;em&gt;&lt;u&gt;your own models&lt;/u&gt;&lt;/em&gt; that are stored in &lt;strong&gt;&lt;em&gt;&lt;u&gt;Amazon S3&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt;, or to use a &lt;em&gt;&lt;u&gt;different machine learning framework&lt;/u&gt;&lt;/em&gt;, you can use the recipes of the following public components as templates to create custom machine learning components.
    &lt;ul&gt;
      &lt;li&gt;Further Reference:
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/greengrass/v2/developerguide/ml-customization.html&quot;&gt;Customize your machine learning components&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;AWS provided ML model components:
    &lt;ul&gt;
      &lt;li&gt;SageMaker Edge Manager&lt;/li&gt;
      &lt;li&gt;DLR image classification&lt;/li&gt;
      &lt;li&gt;DLR object detection&lt;/li&gt;
      &lt;li&gt;DLR image classification model store&lt;/li&gt;
      &lt;li&gt;DLR object detection model store&lt;/li&gt;
      &lt;li&gt;DLR installer&lt;/li&gt;
      &lt;li&gt;TensorFlow Lite image classification&lt;/li&gt;
      &lt;li&gt;TensorFlow Lite object detection&lt;/li&gt;
      &lt;li&gt;TensorFlow Lite image classification model store&lt;/li&gt;
      &lt;li&gt;TensorFlow Lite object detection model store&lt;/li&gt;
      &lt;li&gt;TensorFlow Lite installer&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;aws-sagemaker-edge-manager-agent&quot;&gt;AWS SageMaker Edge Manager agent&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;With SageMaker Edge Manager, you can use Amazon SageMaker Neo-compiled models directly on your core device.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/on-premise%20cloud/cloud/aws/edge%20iot/ml/2021/11/11/AWS-SageMaker.html&quot;&gt;AWS SageMaker Edge Manager&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;further-references&quot;&gt;Further References&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/aws-samples/greengrass-v2-docker-ros-demo&quot;&gt;ROS2 Docker Sample Application with AWS IoT Greengrass 2.0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Akhilesh Moghe</name></author><category term="On-Premise Cloud" /><category term="Cloud" /><category term="AWS" /><category term="Edge IoT" /><category term="On-Premise Cloud" /><category term="Cloud" /><category term="AWS" /><category term="Edge IoT" /><summary type="html">This write-up will only focus on AWS Sagemaker ML service with respect to ML model deployment to Edge devices and Cloud. ML Inference on Greengrass devices ML models can be trained using AWS Sagemaker or custom ml trainining ways. Models are stored in AWS S3 for deployment to Greengrass devices. ML models are deployed as artifacts in your components to perform inference on your core devices. ML Components AWS provides following Machine Learning components that can be deployed to edge devices to perform Machine Learning Inference. ML models can be trained using AWS Sagemaker or custom ml trainining ways. Models are stored in AWS S3 for deployment to Greengrass devices. AWS-provided machine learning components are broadly categorized as follows: Model component — Contains machine learning models as Greengrass artifacts. Runtime component — Contains the script that installs the machine learning framework and its dependencies on the Greengrass core device. Inference component — Contains the inference code and includes component dependencies to install the machine learning framework and download pre-trained machine learning models. To perform custom machine learning inference with your own models that are stored in Amazon S3, or to use a different machine learning framework, you can use the recipes of the following public components as templates to create custom machine learning components. Further Reference: Customize your machine learning components AWS provided ML model components: SageMaker Edge Manager DLR image classification DLR object detection DLR image classification model store DLR object detection model store DLR installer TensorFlow Lite image classification TensorFlow Lite object detection TensorFlow Lite image classification model store TensorFlow Lite object detection model store TensorFlow Lite installer AWS SageMaker Edge Manager agent With SageMaker Edge Manager, you can use Amazon SageMaker Neo-compiled models directly on your core device. AWS SageMaker Edge Manager Further References ROS2 Docker Sample Application with AWS IoT Greengrass 2.0</summary></entry><entry><title type="html">Why prefer Static memory allocation over Dynamic in Embedded Firmmware</title><link href="http://localhost:4000/on-premise%20cloud/cloud/aws/edge%20iot/2021/11/12/Why-Static-Memory-Allocation-Preferred-over-Dynamic-in-Embedded-Firmwares.html" rel="alternate" type="text/html" title="Why prefer Static memory allocation over Dynamic in Embedded Firmmware" /><published>2021-11-12T12:33:22+05:30</published><updated>2021-11-12T12:33:22+05:30</updated><id>http://localhost:4000/on-premise%20cloud/cloud/aws/edge%20iot/2021/11/12/Why-Static-Memory-Allocation-Preferred-over-Dynamic-in-Embedded-Firmwares</id><content type="html" xml:base="http://localhost:4000/on-premise%20cloud/cloud/aws/edge%20iot/2021/11/12/Why-Static-Memory-Allocation-Preferred-over-Dynamic-in-Embedded-Firmwares.html">&lt;p&gt;This write-up will gather the pointers and conclude on why Static memory allocation is preferred over Dynamic memory in Embedded world.&lt;/p&gt;

&lt;h2 id=&quot;options-for-memory-allocation-pros--cons&quot;&gt;Options for Memory Allocation, Pros &amp;amp; Cons&lt;/h2&gt;
&lt;p&gt;Embedded systems have limited amount of Random Access Memory (RAM) which will be used across different types of memory sections like Stack, Heap, data, variables sections.&lt;/p&gt;

&lt;h3 id=&quot;static-memory-allocation-without-stack-or-heap&quot;&gt;Static memory allocation, without Stack or Heap&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;If all of the memory is allocated Statically, the the amount of RAM being used can be determined at Compile time.&lt;/li&gt;
  &lt;li&gt;This avoids the memory-related issues like: memory leaks, dangling pointers, segmentation fault, etc.&lt;/li&gt;
  &lt;li&gt;We have following options to allocate memory for all kind of data:
    &lt;ul&gt;
      &lt;li&gt;Global variables.&lt;/li&gt;
      &lt;li&gt;File Static variables.&lt;/li&gt;
      &lt;li&gt;Function Static Variables.&lt;/li&gt;
      &lt;li&gt;Local variables inside functions.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;8-bit Microcontrollers like 8051 &amp;amp; PIC are usually designed to work with only Static memory.&lt;/li&gt;
  &lt;li&gt;If there is no support for stack in MCU hardware, all the local variables are stored in the same memory location and that memory location is not used by any other function, even if the function is not running.&lt;/li&gt;
  &lt;li&gt;This prohibits the use of recursion or any other mechanism that requires reentrant code.
    &lt;ul&gt;
      &lt;li&gt;e.g. an interrupt routine can’t call a function that may also be called by the main flow of execution.&lt;/li&gt;
      &lt;li&gt;but this guarantees, no memory related run-time issues.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;This provides robustness of the program at the cost of programming flexibility &amp;amp; efficiency.&lt;/li&gt;
  &lt;li&gt;This is only feasible for MCUs which are supposed to run a small system &amp;amp; where memory usage is very limited and can be predetermined exactly.&lt;/li&gt;
  &lt;li&gt;For larger systems, this approach of No Stack, No Heap is not feasible, as it will need enourmous amount of RAM for every individual memory allocation, which each need different memory location.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;stack-based-memory-management&quot;&gt;Stack based memory management&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;A block of memory is allocated on Stack for each invocation of a function and the same is regained after function exits.&lt;/li&gt;
  &lt;li&gt;It’s difficult for a recursive program to predict how much Stack size will be in worst case.&lt;/li&gt;
  &lt;li&gt;A multi-tasking system needs to have a separate Stack for each task.&lt;/li&gt;
  &lt;li&gt;Plus an extra on efor Interrupts.&lt;/li&gt;
  &lt;li&gt;Stack size is usually pre-determined and statically fixed.&lt;/li&gt;
  &lt;li&gt;Stack Overflow is an untimely issue in static stack size allocation, a task may run into it, which the stack of other task is empty at that time.&lt;/li&gt;
  &lt;li&gt;Best Practice:
    &lt;ul&gt;
      &lt;li&gt;Allocate the Stack Size to be 50% more than the worst case seen during testing.&lt;/li&gt;
      &lt;li&gt;Many RTOS systems provide a stack size tracing feature.&lt;/li&gt;
      &lt;li&gt;Check for infinite recursion cases, if any.&lt;/li&gt;
      &lt;li&gt;Check for local variables sizes, specially for large sizes, it may extend beyond the top of stack (stack overflow).&lt;/li&gt;
      &lt;li&gt;Check for large variable arrays &amp;amp; recursive functions, they determine the pattern of stack usage.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heap-based-memory-management&quot;&gt;Heap based memory management&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Heap memory is assigned with malloc() and regained with free() in C.&lt;/li&gt;
  &lt;li&gt;Stack management, i.e. memory allocation and regaining is managed by compiler, but the onus of Heap management relies with the programmer.&lt;/li&gt;
  &lt;li&gt;Heap is a major reason of devious bugs in C programs.
    &lt;ul&gt;
      &lt;li&gt;You freed the memory with free(), but continue to access it with a pointer that is nor NULLED after free() and neither being checked for NULL. This is perfect receipe for untimely crash, unexpected behaviour.&lt;/li&gt;
      &lt;li&gt;You did not freed the memory for later access, but the pointers to that memory itself have gone out of scope. Now you are staring at Memory Leaks, the memory allocations that cannot be regained. It just a matter of time, you will run out of memory due to memory leak tending towards infinity with each call to that buggy code.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Memory Fragmentation:
    &lt;ul&gt;
      &lt;li&gt;This cannot be corrected at the application level.&lt;/li&gt;
      &lt;li&gt;Caused by the blocks of memory available being broken down into smaller pieces as many allocations and frees are performed.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=_G4HJDQjeP8&amp;amp;ab_channel=cpp4arduino&quot;&gt;Memory Heap Fragmentation&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The conclusion is that heap use does involve an element of risk, which the programmer may choose to accept in return for a more flexible, RAM-efficient system.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;memory-pools&quot;&gt;Memory Pools&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Pools, or partitions, of fixed-size memory blocks can be used to completely eliminate the potential for fragmentation.&lt;/li&gt;
  &lt;li&gt;A compromise between static allocation and a general purpose heap.&lt;/li&gt;
  &lt;li&gt;This heap can be tuned at design time for the size of the requests that will be made, as Embedded programs are usually addressing and desined for a particular problem or use-case, not for general purposes.&lt;/li&gt;
  &lt;li&gt;Each pool contains an array of blocks. Unused blocks can be linked together in a list. The pools themselves are declared as arrays.&lt;/li&gt;
  &lt;li&gt;Size is fixed for each pool.&lt;/li&gt;
  &lt;li&gt;This system must be tuned by deciding which size blocks to make available and how many blocks to provide in each pool.&lt;/li&gt;
  &lt;li&gt;Defining pools at sizes which are powers of two (that is, 2, 4, 8, 16, 32, 64, etc.) is a good starting point.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/1725923/how-bad-is-it-to-use-dynamic-datastuctures-on-an-embedded-system&quot;&gt;how bad is it to use dynamic datastuctures on an embedded system?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.nongnu.org/avr-libc/user-manual/malloc.html&quot;&gt;Memory Areas and Using malloc()&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://barrgroup.com/embedded-systems/how-to/malloc-free-dynamic-memory-allocation&quot;&gt;How to Allocate Dynamic Memory Safely&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.embedded.com/use-malloc-why-not/&quot;&gt;Use malloc()? Why not?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/33430900/dynamic-memory-allocation-in-embedded-c&quot;&gt;Dynamic memory allocation in embedded C&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://open4tech.com/concept-heap-usage-embedded-systems/&quot;&gt;The Concept of Heap and Its Usage in Embedded Systems&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.embeddedcomputing.com/technology/software-and-os/ides-application-programming/dynamic-memory-allocation-just-say-no&quot;&gt;Dynamic Memory Allocation - Just Say No&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/21370410/why-shouldnt-we-have-dynamic-allocated-memory-with-different-size-in-embedded-s&quot;&gt;Why shouldn’t we have dynamic allocated memory with different size in embedded system&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.embedded.com/mastering-stack-and-heap-for-system-reliability-part-1-calculating-stack-size/&quot;&gt;Mastering stack and heap for system reliability: Part 1 – Calculating stack size&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.embedded.com/dynamic-memory-and-heap-contiguity/&quot;&gt;Dynamic memory and heap contiguity&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/37812732/use-of-malloc-in-embedded-c/37814174&quot;&gt;use of malloc in embedded c [closed]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Akhilesh Moghe</name></author><category term="On-Premise Cloud" /><category term="Cloud" /><category term="AWS" /><category term="Edge IoT" /><category term="On-Premise Cloud" /><category term="Cloud" /><category term="AWS" /><category term="Edge IoT" /><summary type="html">This write-up will gather the pointers and conclude on why Static memory allocation is preferred over Dynamic memory in Embedded world. Options for Memory Allocation, Pros &amp;amp; Cons Embedded systems have limited amount of Random Access Memory (RAM) which will be used across different types of memory sections like Stack, Heap, data, variables sections. Static memory allocation, without Stack or Heap If all of the memory is allocated Statically, the the amount of RAM being used can be determined at Compile time. This avoids the memory-related issues like: memory leaks, dangling pointers, segmentation fault, etc. We have following options to allocate memory for all kind of data: Global variables. File Static variables. Function Static Variables. Local variables inside functions. 8-bit Microcontrollers like 8051 &amp;amp; PIC are usually designed to work with only Static memory. If there is no support for stack in MCU hardware, all the local variables are stored in the same memory location and that memory location is not used by any other function, even if the function is not running. This prohibits the use of recursion or any other mechanism that requires reentrant code. e.g. an interrupt routine can’t call a function that may also be called by the main flow of execution. but this guarantees, no memory related run-time issues. This provides robustness of the program at the cost of programming flexibility &amp;amp; efficiency. This is only feasible for MCUs which are supposed to run a small system &amp;amp; where memory usage is very limited and can be predetermined exactly. For larger systems, this approach of No Stack, No Heap is not feasible, as it will need enourmous amount of RAM for every individual memory allocation, which each need different memory location. Stack based memory management A block of memory is allocated on Stack for each invocation of a function and the same is regained after function exits. It’s difficult for a recursive program to predict how much Stack size will be in worst case. A multi-tasking system needs to have a separate Stack for each task. Plus an extra on efor Interrupts. Stack size is usually pre-determined and statically fixed. Stack Overflow is an untimely issue in static stack size allocation, a task may run into it, which the stack of other task is empty at that time. Best Practice: Allocate the Stack Size to be 50% more than the worst case seen during testing. Many RTOS systems provide a stack size tracing feature. Check for infinite recursion cases, if any. Check for local variables sizes, specially for large sizes, it may extend beyond the top of stack (stack overflow). Check for large variable arrays &amp;amp; recursive functions, they determine the pattern of stack usage. Heap based memory management Heap memory is assigned with malloc() and regained with free() in C. Stack management, i.e. memory allocation and regaining is managed by compiler, but the onus of Heap management relies with the programmer. Heap is a major reason of devious bugs in C programs. You freed the memory with free(), but continue to access it with a pointer that is nor NULLED after free() and neither being checked for NULL. This is perfect receipe for untimely crash, unexpected behaviour. You did not freed the memory for later access, but the pointers to that memory itself have gone out of scope. Now you are staring at Memory Leaks, the memory allocations that cannot be regained. It just a matter of time, you will run out of memory due to memory leak tending towards infinity with each call to that buggy code. Memory Fragmentation: This cannot be corrected at the application level. Caused by the blocks of memory available being broken down into smaller pieces as many allocations and frees are performed. Memory Heap Fragmentation The conclusion is that heap use does involve an element of risk, which the programmer may choose to accept in return for a more flexible, RAM-efficient system. Memory Pools Pools, or partitions, of fixed-size memory blocks can be used to completely eliminate the potential for fragmentation. A compromise between static allocation and a general purpose heap. This heap can be tuned at design time for the size of the requests that will be made, as Embedded programs are usually addressing and desined for a particular problem or use-case, not for general purposes. Each pool contains an array of blocks. Unused blocks can be linked together in a list. The pools themselves are declared as arrays. Size is fixed for each pool. This system must be tuned by deciding which size blocks to make available and how many blocks to provide in each pool. Defining pools at sizes which are powers of two (that is, 2, 4, 8, 16, 32, 64, etc.) is a good starting point. References how bad is it to use dynamic datastuctures on an embedded system? Memory Areas and Using malloc() How to Allocate Dynamic Memory Safely Use malloc()? Why not? Dynamic memory allocation in embedded C The Concept of Heap and Its Usage in Embedded Systems Dynamic Memory Allocation - Just Say No Why shouldn’t we have dynamic allocated memory with different size in embedded system Mastering stack and heap for system reliability: Part 1 – Calculating stack size Dynamic memory and heap contiguity use of malloc in embedded c [closed]</summary></entry><entry><title type="html">AWS Sagemaker Machine Learning Service, Sagemaker Neo, Sagemaker Edge Manager</title><link href="http://localhost:4000/on-premise%20cloud/cloud/aws/edge%20iot/ml/2021/11/11/AWS-SageMaker.html" rel="alternate" type="text/html" title="AWS Sagemaker Machine Learning Service, Sagemaker Neo, Sagemaker Edge Manager" /><published>2021-11-11T12:33:22+05:30</published><updated>2021-11-11T12:33:22+05:30</updated><id>http://localhost:4000/on-premise%20cloud/cloud/aws/edge%20iot/ml/2021/11/11/AWS-SageMaker</id><content type="html" xml:base="http://localhost:4000/on-premise%20cloud/cloud/aws/edge%20iot/ml/2021/11/11/AWS-SageMaker.html">&lt;p&gt;This write-up will only focus on AWS Sagemaker ML service with respect to ML model deployment to Edge devices and Cloud.&lt;/p&gt;

&lt;h2 id=&quot;aws-sagemaker-neo&quot;&gt;AWS Sagemaker Neo&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Amazon SageMaker Neo enables developers to optimize machine learning (ML) models for inference on SageMaker in the cloud and supported devices at the edge for the specific underlying hardware.&lt;/li&gt;
  &lt;li&gt;Optimizes machine learning models for inference on cloud instances and edge devices to run faster with no loss in accuracy.&lt;/li&gt;
  &lt;li&gt;Amazon SageMaker &lt;strong&gt;&lt;em&gt;&lt;u&gt;Neo runtime&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt; is supported on &lt;em&gt;&lt;u&gt;Android&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;iOS&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;Linux&lt;/u&gt;&lt;/em&gt;, and &lt;em&gt;&lt;u&gt;Windows&lt;/u&gt;&lt;/em&gt; operating systems.&lt;/li&gt;
  &lt;li&gt;Sagemaker neo can optimize the ML model to run on &lt;em&gt;&lt;u&gt;target hardware platform&lt;/u&gt;&lt;/em&gt; of Edge devices based on processors from &lt;em&gt;&lt;u&gt;Ambarella&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;Apple&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;ARM&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;Intel&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;MediaTek&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;Nvidia&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;NXP&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;Qualcomm&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;RockChip&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;Texas Instruments&lt;/u&gt;&lt;/em&gt;, or &lt;em&gt;&lt;u&gt;Xilinx&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Compiles it into an &lt;em&gt;&lt;u&gt;executable&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;For inference in the cloud, SageMaker Neo speeds up inference and saves cost by creating &lt;em&gt;&lt;u&gt;an inference optimized container&lt;/u&gt;&lt;/em&gt; that include &lt;em&gt;&lt;u&gt;MXNet&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;PyTorch&lt;/u&gt;&lt;/em&gt;, and &lt;em&gt;&lt;u&gt;TensorFlow&lt;/u&gt;&lt;/em&gt; integrated with Neo runtime for SageMaker hosting.&lt;/li&gt;
  &lt;li&gt;Amazon SageMaker Neo supports optimization for a model from the framework-specific format of &lt;em&gt;&lt;u&gt;DarkNet&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;Keras&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;MXNet&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;PyTorch&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;TensorFlow&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;TensorFlow-Lite&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;ONNX&lt;/u&gt;&lt;/em&gt;, or &lt;em&gt;&lt;u&gt;XGBoost&lt;/u&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Amazon SageMaker &lt;em&gt;&lt;u&gt;Neo runtime&lt;/u&gt;&lt;/em&gt; occupies 1MB of storage and 2MB of memory, which is many times smaller than the storage and memory footprint of a framework, while providing a simple common &lt;em&gt;&lt;u&gt;API to run a compiled model&lt;/u&gt;&lt;/em&gt; originating in any framework.&lt;/li&gt;
  &lt;li&gt;Amazon SageMaker Neo takes advantage of partner-provided &lt;u&gt;accelerator libraries&lt;/u&gt; to deliver the best available performance for a deep learning model on heterogeneous hardware platforms with a &lt;u&gt;hardware accelerator&lt;/u&gt; as well as a CPU. Acceleration libraries such as &lt;em&gt;&lt;u&gt;Ambarella CV Tools&lt;/u&gt;&lt;/em&gt;, &lt;em&gt;&lt;u&gt;Nvidia Tensor RT&lt;/u&gt;&lt;/em&gt;, and &lt;em&gt;&lt;u&gt;Texas Instruments TIDL&lt;/u&gt;&lt;/em&gt; each support a specific set of functions and operators. SageMaker Neo automatically partitions your model so that the part with operators supported by the accelerator can run on the accelerator while the rest of the model runs on the CPU.&lt;/li&gt;
  &lt;li&gt;Amazon SageMaker Neo now compiles models for Amazon SageMaker &lt;strong&gt;&lt;em&gt;&lt;u&gt;INF1 instance&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt; targets. SageMaker hosting provides a managed service for inference on the INF1 instances, which are based on the &lt;strong&gt;&lt;em&gt;&lt;u&gt;AWS Inferentia chip&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/sagemaker/neo/&quot;&gt;Amazon SageMaker Neo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;aws-sagemaker-edge-manager&quot;&gt;AWS Sagemaker Edge Manager&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;AWS Sagemaker Edge Manager consists of a Service running in AWS cloud and an Agent running on Edge devices.&lt;/li&gt;
  &lt;li&gt;Sagemaker Edge Manager deploys a ML model &lt;em&gt;&lt;u&gt;optimized&lt;/u&gt;&lt;/em&gt; with &lt;em&gt;&lt;u&gt;SageMaker Neo&lt;/u&gt;&lt;/em&gt; automatically so you don’t need to have Neo runtime installed on your devices in order to take advantage of the model optimizations.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;agent&quot;&gt;Agent&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Use the agent to &lt;em&gt;&lt;u&gt;make predictions&lt;/u&gt;&lt;/em&gt; with models loaded onto your edge devices.&lt;/li&gt;
  &lt;li&gt;The agent also &lt;em&gt;&lt;u&gt;collects model metrics&lt;/u&gt; and *&lt;u&gt;captures data&lt;/u&gt;&lt;/em&gt; at specific intervals.&lt;/li&gt;
  &lt;li&gt;Sample data is stored in your &lt;strong&gt;&lt;em&gt;&lt;u&gt;Amazon S3&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt; bucket.&lt;/li&gt;
  &lt;li&gt;2 methods of installing and deploying the Edge Manager agent onto your edge devices:
    &lt;ul&gt;
      &lt;li&gt;Download the &lt;em&gt;&lt;u&gt;agent as a binary&lt;/u&gt;&lt;/em&gt; from the Amazon S3 release bucket.&lt;/li&gt;
      &lt;li&gt;Use the &lt;strong&gt;&lt;em&gt;&lt;u&gt;AWS IoT Greengrass V2&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt; console or the &lt;strong&gt;&lt;em&gt;&lt;u&gt;AWS CLI&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt; to deploy aws.greengrass.SageMakerEdgeManager.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;monitoring-deployments-across-fleets&quot;&gt;Monitoring deployments across fleets&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;SageMaker Edge Manager also &lt;em&gt;&lt;u&gt;collects prediction data and sends&lt;/u&gt;&lt;/em&gt; a sample of the data to the cloud for monitoring, labeling, and retraining.&lt;/li&gt;
  &lt;li&gt;All data can be viewed in the &lt;strong&gt;&lt;em&gt;&lt;u&gt;SageMaker Edge Manager dashboard&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt; which reports on the operation of deployed models.&lt;/li&gt;
  &lt;li&gt;The dashboard is useful to understand the performance of models running on each device across your fleet, understand overall fleet health and identify problematic models and particular devices.&lt;/li&gt;
  &lt;li&gt;If quality declines are detected, you can quickly spot them in the dashboard and also configure alerts through &lt;strong&gt;&lt;em&gt;&lt;u&gt;Amazon CloudWatch&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;signed-and-verifiable-ml-deployments&quot;&gt;Signed and Verifiable ML deployments&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;SageMaker Edge Manager also &lt;em&gt;&lt;u&gt;cryptographically signs your models&lt;/u&gt;&lt;/em&gt; so you can verify that it was not tampered with as it moves from the cloud to edge devices.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;integration-with-device-applications&quot;&gt;Integration with device applications&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;SageMaker Edge Manager &lt;em&gt;&lt;u&gt;supports&lt;/u&gt;&lt;/em&gt; &lt;strong&gt;&lt;em&gt;&lt;u&gt;gRPC&lt;/u&gt;&lt;/em&gt;&lt;/strong&gt;, an open source &lt;em&gt;&lt;u&gt;remote procedure call&lt;/u&gt;&lt;/em&gt;, which allows you to integrate SageMaker Edge Manager with your existing edge applications through APIs in common programming languages, such as Android Java, C# / .NET, Dart, Go, Java, Kotlin/JVM, Node.js, Objective-C, PHP, Python, Ruby, and Web.&lt;/li&gt;
  &lt;li&gt;Manages models separately from the rest of the application, so that updates to the model and the application are independent.
    &lt;h3 id=&quot;multiple-ml-models-serve-on-edge-devices&quot;&gt;Multiple ML models serve on edge devices&lt;/h3&gt;
  &lt;/li&gt;
  &lt;li&gt;ML applications usually require hosting and running multiple models concurrently on a device.&lt;/li&gt;
  &lt;li&gt;SageMaker Edge Manager will soon allow you to write &lt;em&gt;simple application logic&lt;/em&gt; to send one or more queries (i.e. load/unload models, run inference) &lt;em&gt;&lt;u&gt;independently to multiple models&lt;/u&gt;&lt;/em&gt; and &lt;em&gt;&lt;u&gt;rebalance hardware resource utilization&lt;/u&gt;&lt;/em&gt; when you add or update a model.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;model-registry-and-lifecycle&quot;&gt;Model Registry and Lifecycle&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;SageMaker Edge Manager will soon be able to automate the build-train-deploy workflow from cloud to edge devices in Amazon SageMaker Edge Manager, and trace the lifecycle of each model.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=zS0Q3bdsLiU&amp;amp;t=3s&amp;amp;ab_channel=AmazonWebServices&quot;&gt;Sagemaker Edge Manager YouTube&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/sagemaker/latest/dg/edge.html&quot;&gt;Developer Guide: SageMaker Edge Manager&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/sagemaker/latest/dg/edge-device-fleet-about.html&quot;&gt;Developer Guide: Edge Manager Agent&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_edge_manager/sagemaker_edge_example/sagemaker_edge_example.html?highlight=edge&quot;&gt;SageMaker Edge Manager Example&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;aws-outpost-and-aws-sagemaker-edge-manager&quot;&gt;AWS Outpost and AWS Sagemaker Edge Manager&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/blogs/machine-learning/machine-learning-at-the-edge-with-aws-outposts-and-amazon-sagemaker/&quot;&gt;Machine Learning at the Edge with AWS Outposts and Amazon SageMaker&lt;/a&gt;
  &lt;img src=&quot;/assets/images/aws/aws-outpost-sagemaker-edge-manager.png&quot; alt=&quot;aws-outpost-sagemaker-edge-manager&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Akhilesh Moghe</name></author><category term="On-Premise Cloud" /><category term="Cloud" /><category term="AWS" /><category term="Edge IoT" /><category term="ML" /><category term="On-Premise Cloud" /><category term="Cloud" /><category term="AWS" /><category term="Edge IoT" /><category term="ML" /><summary type="html">This write-up will only focus on AWS Sagemaker ML service with respect to ML model deployment to Edge devices and Cloud. AWS Sagemaker Neo Amazon SageMaker Neo enables developers to optimize machine learning (ML) models for inference on SageMaker in the cloud and supported devices at the edge for the specific underlying hardware. Optimizes machine learning models for inference on cloud instances and edge devices to run faster with no loss in accuracy. Amazon SageMaker Neo runtime is supported on Android, iOS, Linux, and Windows operating systems. Sagemaker neo can optimize the ML model to run on target hardware platform of Edge devices based on processors from Ambarella, Apple, ARM, Intel, MediaTek, Nvidia, NXP, Qualcomm, RockChip, Texas Instruments, or Xilinx. Compiles it into an executable. For inference in the cloud, SageMaker Neo speeds up inference and saves cost by creating an inference optimized container that include MXNet, PyTorch, and TensorFlow integrated with Neo runtime for SageMaker hosting. Amazon SageMaker Neo supports optimization for a model from the framework-specific format of DarkNet, Keras, MXNet, PyTorch, TensorFlow, TensorFlow-Lite, ONNX, or XGBoost. Amazon SageMaker Neo runtime occupies 1MB of storage and 2MB of memory, which is many times smaller than the storage and memory footprint of a framework, while providing a simple common API to run a compiled model originating in any framework. Amazon SageMaker Neo takes advantage of partner-provided accelerator libraries to deliver the best available performance for a deep learning model on heterogeneous hardware platforms with a hardware accelerator as well as a CPU. Acceleration libraries such as Ambarella CV Tools, Nvidia Tensor RT, and Texas Instruments TIDL each support a specific set of functions and operators. SageMaker Neo automatically partitions your model so that the part with operators supported by the accelerator can run on the accelerator while the rest of the model runs on the CPU. Amazon SageMaker Neo now compiles models for Amazon SageMaker INF1 instance targets. SageMaker hosting provides a managed service for inference on the INF1 instances, which are based on the AWS Inferentia chip. References Amazon SageMaker Neo AWS Sagemaker Edge Manager AWS Sagemaker Edge Manager consists of a Service running in AWS cloud and an Agent running on Edge devices. Sagemaker Edge Manager deploys a ML model optimized with SageMaker Neo automatically so you don’t need to have Neo runtime installed on your devices in order to take advantage of the model optimizations. Agent Use the agent to make predictions with models loaded onto your edge devices. The agent also collects model metrics and *captures data at specific intervals. Sample data is stored in your Amazon S3 bucket. 2 methods of installing and deploying the Edge Manager agent onto your edge devices: Download the agent as a binary from the Amazon S3 release bucket. Use the AWS IoT Greengrass V2 console or the AWS CLI to deploy aws.greengrass.SageMakerEdgeManager. Monitoring deployments across fleets SageMaker Edge Manager also collects prediction data and sends a sample of the data to the cloud for monitoring, labeling, and retraining. All data can be viewed in the SageMaker Edge Manager dashboard which reports on the operation of deployed models. The dashboard is useful to understand the performance of models running on each device across your fleet, understand overall fleet health and identify problematic models and particular devices. If quality declines are detected, you can quickly spot them in the dashboard and also configure alerts through Amazon CloudWatch. Signed and Verifiable ML deployments SageMaker Edge Manager also cryptographically signs your models so you can verify that it was not tampered with as it moves from the cloud to edge devices. Integration with device applications SageMaker Edge Manager supports gRPC, an open source remote procedure call, which allows you to integrate SageMaker Edge Manager with your existing edge applications through APIs in common programming languages, such as Android Java, C# / .NET, Dart, Go, Java, Kotlin/JVM, Node.js, Objective-C, PHP, Python, Ruby, and Web. Manages models separately from the rest of the application, so that updates to the model and the application are independent. Multiple ML models serve on edge devices ML applications usually require hosting and running multiple models concurrently on a device. SageMaker Edge Manager will soon allow you to write simple application logic to send one or more queries (i.e. load/unload models, run inference) independently to multiple models and rebalance hardware resource utilization when you add or update a model. Model Registry and Lifecycle SageMaker Edge Manager will soon be able to automate the build-train-deploy workflow from cloud to edge devices in Amazon SageMaker Edge Manager, and trace the lifecycle of each model. Reference Sagemaker Edge Manager YouTube Developer Guide: SageMaker Edge Manager Developer Guide: Edge Manager Agent SageMaker Edge Manager Example AWS Outpost and AWS Sagemaker Edge Manager Machine Learning at the Edge with AWS Outposts and Amazon SageMaker</summary></entry></feed>